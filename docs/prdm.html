<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Point Referenced Data Modeling | REST Scraping API for Real Estate data, a Spatial Bayesian modeling perspective with INLA</title>
  <meta name="description" content="Niccolò Salvini master’s thesis project" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Point Referenced Data Modeling | REST Scraping API for Real Estate data, a Spatial Bayesian modeling perspective with INLA" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://niccolosalvini.github.io/Thesis/" />
  <meta property="og:image" content="https://niccolosalvini.github.io/Thesis/images/spat-touch.png" />
  <meta property="og:description" content="Niccolò Salvini master’s thesis project" />
  <meta name="github-repo" content="NiccoloSalvini/Thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Point Referenced Data Modeling | REST Scraping API for Real Estate data, a Spatial Bayesian modeling perspective with INLA" />
  
  <meta name="twitter:description" content="Niccolò Salvini master’s thesis project" />
  <meta name="twitter:image" content="https://niccolosalvini.github.io/Thesis/images/spat-touch.png" />

<meta name="author" content="Niccolò Salvini" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="images/spatial.png" />
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="inla.html"/>
<link rel="next" href="spde.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>
<link href="libs/leaflet-minimap-3.3.1/Control.MiniMap.min.css" rel="stylesheet" />
<script src="libs/leaflet-minimap-3.3.1/Control.MiniMap.min.js"></script>
<script src="libs/leaflet-minimap-3.3.1/Minimap-binding.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-171723874-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-171723874-1');
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="images/transspatial.PNG"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminary Content</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#abstract"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="scraping.html"><a href="scraping.html"><i class="fa fa-check"></i><b>2</b> Web Scraping</a><ul>
<li class="chapter" data-level="2.1" data-path="scraping.html"><a href="scraping.html#web-scraping"><i class="fa fa-check"></i><b>2.1</b> Web Scraping</a></li>
<li class="chapter" data-level="2.2" data-path="scraping.html"><a href="scraping.html#graph-representation-of-html"><i class="fa fa-check"></i><b>2.2</b> Graph Representation of HTML</a></li>
<li class="chapter" data-level="2.3" data-path="scraping.html"><a href="scraping.html#crawling"><i class="fa fa-check"></i><b>2.3</b> Crawling</a></li>
<li class="chapter" data-level="2.4" data-path="scraping.html"><a href="scraping.html#proper-scraping"><i class="fa fa-check"></i><b>2.4</b> Proper Scraping</a><ul>
<li class="chapter" data-level="2.4.1" data-path="scraping.html"><a href="scraping.html#webstructure"><i class="fa fa-check"></i><b>2.4.1</b> Immobiliare.it website structure</a></li>
<li class="chapter" data-level="2.4.2" data-path="scraping.html"><a href="scraping.html#immobiliare.it-content-architecture-with-rvest"><i class="fa fa-check"></i><b>2.4.2</b> Immobiliare.it content architecture with <code id="ContentArchitecture">rvest</code></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="scraping.html"><a href="scraping.html#ProperScraping"><i class="fa fa-check"></i><b>2.5</b> Proper Scarping</a></li>
<li class="chapter" data-level="2.6" data-path="scraping.html"><a href="scraping.html#best-practices"><i class="fa fa-check"></i><b>2.6</b> Scraping Best Practices and Security provisions</a></li>
<li class="chapter" data-level="2.7" data-path="scraping.html"><a href="scraping.html#web-client-security-provisions-user-agents-proxies-and-fail-dealers"><i class="fa fa-check"></i><b>2.7</b> Web Client Security provisions: User Agents, Proxies and Fail Dealers</a><ul>
<li class="chapter" data-level="2.7.1" data-path="scraping.html"><a href="scraping.html#spoofing"><i class="fa fa-check"></i><b>2.7.1</b> HTTP User Agent and Mail Spoofing</a></li>
<li class="chapter" data-level="2.7.2" data-path="scraping.html"><a href="scraping.html#possibly"><i class="fa fa-check"></i><b>2.7.2</b> Dealing with failure</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="scraping.html"><a href="scraping.html#parallelscraping"><i class="fa fa-check"></i><b>2.8</b> Parallel Scraping</a><ul>
<li class="chapter" data-level="2.8.1" data-path="scraping.html"><a href="scraping.html#parallel-furrrfuture"><i class="fa fa-check"></i><b>2.8.1</b> Parallel furrr+future</a></li>
<li class="chapter" data-level="2.8.2" data-path="scraping.html"><a href="scraping.html#parallel-foreachdofuture"><i class="fa fa-check"></i><b>2.8.2</b> Parallel foreach+doFuture</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="scraping.html"><a href="scraping.html#challenges"><i class="fa fa-check"></i><b>2.9</b> Open Challenges and Further Improvemements</a></li>
<li class="chapter" data-level="2.10" data-path="scraping.html"><a href="scraping.html#legal-profiles"><i class="fa fa-check"></i><b>2.10</b> Legal Profiles</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Infrastructure.html"><a href="Infrastructure.html"><i class="fa fa-check"></i><b>3</b> API Technologies Stack</a><ul>
<li class="chapter" data-level="3.1" data-path="Infrastructure.html"><a href="Infrastructure.html#scheduler"><i class="fa fa-check"></i><b>3.1</b> Scheduler</a><ul>
<li class="chapter" data-level="3.1.1" data-path="Infrastructure.html"><a href="Infrastructure.html#cron-jobs"><i class="fa fa-check"></i><b>3.1.1</b> Cron Jobs</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="Infrastructure.html"><a href="Infrastructure.html#rest-api"><i class="fa fa-check"></i><b>3.2</b> REST API</a><ul>
<li class="chapter" data-level="3.2.1" data-path="Infrastructure.html"><a href="Infrastructure.html#plumberapi"><i class="fa fa-check"></i><b>3.2.1</b> Plumber REST API</a></li>
<li class="chapter" data-level="3.2.2" data-path="Infrastructure.html"><a href="Infrastructure.html#immobiliare.it-parallel-rest-api"><i class="fa fa-check"></i><b>3.2.2</b> Immobiliare.it <em>Parallel</em> REST API</a></li>
<li class="chapter" data-level="3.2.3" data-path="Infrastructure.html"><a href="Infrastructure.html#APIdocs"><i class="fa fa-check"></i><b>3.2.3</b> REST API documentation</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="Infrastructure.html"><a href="Infrastructure.html#docker"><i class="fa fa-check"></i><b>3.3</b> Docker</a><ul>
<li class="chapter" data-level="3.3.1" data-path="Infrastructure.html"><a href="Infrastructure.html#why-docker"><i class="fa fa-check"></i><b>3.3.1</b> Why Docker</a></li>
<li class="chapter" data-level="3.3.2" data-path="Infrastructure.html"><a href="Infrastructure.html#dockerfile"><i class="fa fa-check"></i><b>3.3.2</b> Dockerfile</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="Infrastructure.html"><a href="Infrastructure.html#aws"><i class="fa fa-check"></i><b>3.4</b> AWS EC2 instance</a><ul>
<li class="chapter" data-level="3.4.1" data-path="Infrastructure.html"><a href="Infrastructure.html#launch-an-ec2-instance"><i class="fa fa-check"></i><b>3.4.1</b> Launch an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="Infrastructure.html"><a href="Infrastructure.html#nginx"><i class="fa fa-check"></i><b>3.5</b> NGINX reverse proxy server</a></li>
<li class="chapter" data-level="3.6" data-path="Infrastructure.html"><a href="Infrastructure.html#software-development-workflow"><i class="fa fa-check"></i><b>3.6</b> Software development Workflow</a></li>
<li class="chapter" data-level="3.7" data-path="Infrastructure.html"><a href="Infrastructure.html#further-integrations"><i class="fa fa-check"></i><b>3.7</b> Further Integrations</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inla.html"><a href="inla.html"><i class="fa fa-check"></i><b>4</b> INLA computation</a><ul>
<li class="chapter" data-level="4.1" data-path="inla.html"><a href="inla.html#LGM"><i class="fa fa-check"></i><b>4.1</b> Latent Gaussian Models LGM</a></li>
<li class="chapter" data-level="4.2" data-path="inla.html"><a href="inla.html#approx"><i class="fa fa-check"></i><b>4.2</b> Approximation in INLA setting</a><ul>
<li class="chapter" data-level="4.2.1" data-path="inla.html"><a href="inla.html#further-approximations-prolly-do-not-note-include"><i class="fa fa-check"></i><b>4.2.1</b> further approximations (prolly do not note include)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="inla.html"><a href="inla.html#rinla"><i class="fa fa-check"></i><b>4.3</b> R-INLA package in a bayesian hierarchical regression perspective</a><ul>
<li class="chapter" data-level="4.3.1" data-path="inla.html"><a href="inla.html#overview"><i class="fa fa-check"></i><b>4.3.1</b> Overview</a></li>
<li class="chapter" data-level="4.3.2" data-path="inla.html"><a href="inla.html#example"><i class="fa fa-check"></i><b>4.3.2</b> Linear Predictor</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="prdm.html"><a href="prdm.html"><i class="fa fa-check"></i><b>5</b> Point Referenced Data Modeling</a><ul>
<li class="chapter" data-level="5.1" data-path="prdm.html"><a href="prdm.html#GP"><i class="fa fa-check"></i><b>5.1</b> Gaussian Process (GP)</a></li>
<li class="chapter" data-level="5.2" data-path="prdm.html"><a href="prdm.html#spatial-covariance-function"><i class="fa fa-check"></i><b>5.2</b> Spatial Covariance Function</a><ul>
<li class="chapter" data-level="5.2.1" data-path="prdm.html"><a href="prdm.html#Matern"><i class="fa fa-check"></i><b>5.2.1</b> Matérn Covariance Function</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="prdm.html"><a href="prdm.html#hedonic-models-literature-review-and-spatial-hedonic-price-models"><i class="fa fa-check"></i><b>5.3</b> Hedonic models Literature Review and Spatial Hedonic Price Models</a></li>
<li class="chapter" data-level="5.4" data-path="prdm.html"><a href="prdm.html#univariateregr"><i class="fa fa-check"></i><b>5.4</b> Point Referenced Regression for univariate spatial data</a></li>
<li class="chapter" data-level="5.5" data-path="prdm.html"><a href="prdm.html#hiermod"><i class="fa fa-check"></i><b>5.5</b> Hierarchical Bayesian models</a></li>
<li class="chapter" data-level="5.6" data-path="prdm.html"><a href="prdm.html#finalregr"><i class="fa fa-check"></i><b>5.6</b> INLA model through spatial hierarchical regression</a></li>
<li class="chapter" data-level="5.7" data-path="prdm.html"><a href="prdm.html#spatial-kriging"><i class="fa fa-check"></i><b>5.7</b> Spatial Kriging</a></li>
<li class="chapter" data-level="5.8" data-path="prdm.html"><a href="prdm.html#model-checking"><i class="fa fa-check"></i><b>5.8</b> Model Checking</a></li>
<li class="chapter" data-level="5.9" data-path="prdm.html"><a href="prdm.html#prior-specification"><i class="fa fa-check"></i><b>5.9</b> Prior Specification</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="spde.html"><a href="spde.html"><i class="fa fa-check"></i><b>6</b> SPDE approach</a><ul>
<li class="chapter" data-level="6.1" data-path="spde.html"><a href="spde.html#set-spde-problem"><i class="fa fa-check"></i><b>6.1</b> Set SPDE Problem</a></li>
<li class="chapter" data-level="6.2" data-path="spde.html"><a href="spde.html#spde-within-r-inla"><i class="fa fa-check"></i><b>6.2</b> SPDE within R-INLA</a></li>
<li class="chapter" data-level="6.3" data-path="spde.html"><a href="spde.html#first-point-krainsky-rubio-too-technical"><i class="fa fa-check"></i><b>6.3</b> First Point Krainsky Rubio TOO TECHNICAL</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="exploratory.html"><a href="exploratory.html"><i class="fa fa-check"></i><b>7</b> Exploratory Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="exploratory.html"><a href="exploratory.html#prep"><i class="fa fa-check"></i><b>7.1</b> Data preparation</a><ul>
<li class="chapter" data-level="7.1.1" data-path="exploratory.html"><a href="exploratory.html#maps-and-geo-visualisations"><i class="fa fa-check"></i><b>7.1.1</b> Maps and Geo-Visualisations</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="exploratory.html"><a href="exploratory.html#counts-and-first-orientations"><i class="fa fa-check"></i><b>7.2</b> Counts and First Orientations</a></li>
<li class="chapter" data-level="7.3" data-path="exploratory.html"><a href="exploratory.html#text-mining-in-estate-review"><i class="fa fa-check"></i><b>7.3</b> Text Mining in estate Review</a></li>
<li class="chapter" data-level="7.4" data-path="exploratory.html"><a href="exploratory.html#missing-assessement-and-imputation"><i class="fa fa-check"></i><b>7.4</b> Missing Assessement and Imputation</a><ul>
<li class="chapter" data-level="7.4.1" data-path="exploratory.html"><a href="exploratory.html#missing-assessement"><i class="fa fa-check"></i><b>7.4.1</b> Missing assessement</a></li>
<li class="chapter" data-level="7.4.2" data-path="exploratory.html"><a href="exploratory.html#covariates-imputation"><i class="fa fa-check"></i><b>7.4.2</b> Covariates Imputation</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="exploratory.html"><a href="exploratory.html#model-specification"><i class="fa fa-check"></i><b>7.5</b> Model Specification</a></li>
<li class="chapter" data-level="7.6" data-path="exploratory.html"><a href="exploratory.html#mesh-building"><i class="fa fa-check"></i><b>7.6</b> Mesh building</a><ul>
<li class="chapter" data-level="7.6.1" data-path="exploratory.html"><a href="exploratory.html#shinyapp-for-mesh-assessment"><i class="fa fa-check"></i><b>7.6.1</b> Shinyapp for mesh assessment</a></li>
<li class="chapter" data-level="7.6.2" data-path="exploratory.html"><a href="exploratory.html#building-spde-model-on-mesh"><i class="fa fa-check"></i><b>7.6.2</b> BUilding SPDE model on mesh</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="exploratory.html"><a href="exploratory.html#spatial-kriging-prediction"><i class="fa fa-check"></i><b>7.7</b> Spatial Kriging (Prediction)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelspec.html"><a href="modelspec.html"><i class="fa fa-check"></i><b>8</b> Model Selection &amp; Fitting</a><ul>
<li class="chapter" data-level="8.1" data-path="modelspec.html"><a href="modelspec.html#model-criticism"><i class="fa fa-check"></i><b>8.1</b> Model Criticism</a></li>
<li class="chapter" data-level="8.2" data-path="modelspec.html"><a href="modelspec.html#spatial-kriging-1"><i class="fa fa-check"></i><b>8.2</b> Spatial Kriging</a></li>
<li class="chapter" data-level="8.3" data-path="modelspec.html"><a href="modelspec.html#model-checking-1"><i class="fa fa-check"></i><b>8.3</b> Model Checking</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="application.html"><a href="application.html"><i class="fa fa-check"></i><b>9</b> Shiny Application</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="9.1" data-path="appendix.html"><a href="appendix.html#gp-basics"><i class="fa fa-check"></i><b>9.1</b> GP basics</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/NiccoloSalvini/tesi-prova" target="blank"> See Github Repository</a></li>
<li><a href="https://niccolosalvini.netlify.app/">About The Author</a></li>
<li><a Proudly published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">REST Scraping API for Real Estate data, a Spatial Bayesian modeling perspective with INLA</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prdm" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Point Referenced Data Modeling</h1>
<p>Geostatistical data are a collection of samples of geo type data indexed by coordinates (e.g. latlong, eastings and northings) that originate from a spatially continuous phenomenon <span class="citation">(Moraga <a href="#ref-Moraga2019" role="doc-biblioref">2019</a>)</span>. Data as such can monitor a vast range of phenomena, as an example disease cancer detection <span class="citation">(Bell et al. <a href="#ref-Bell2006" role="doc-biblioref">2006</a>)</span> at several sites, COVID19 spread in China <span class="citation">(Li et al. <a href="#ref-Li_Li_Ding_Hu_Chen_Wang_Peng_Shen_2020" role="doc-biblioref">2020</a>)</span>, PM pollution concentration in a North-Italian region Piemonte <span class="citation">(Cameletti et al. <a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span>. Moreover house prices variation, as observed in <span class="citation">Gómez Rubio (<a href="#ref-Bayesian_INLA_Rubio" role="doc-biblioref">2020</a>)</span>, where selling prices smoothly vary between closer neighborhoods. All the Examples taken before might document a spatial nature of data according to which closer observations can display similar values, this phenomenon is named spatial autocorrelation. Spatial autocorrelation conceptually originates from geographer Waldo Tobler whose famous quote, known as first law of geography, inspires geostatisticians:</p>
<blockquote>
<p>“Everything is related to everything else,
but near things are more related than distant things”</p>
<footer>
— Waldo R. Tobler
</footer>
</blockquote>
<p>Spatial models are explicitly designed to take into account this behavior and can separate spatial patterns from simply random spatial variance.
Spatial data can be partitioned into three spatial data type whose modeling tools are specific with respect to their category.</p>
<ul>
<li>Areal Data</li>
<li><strong>Point Referenced Data</strong></li>
<li>Point Pattern Data</li>
</ul>
<!-- Potrei mettere lealfet interattivo ma si rovina nella conversione latex
rimane da provare:
- salvarlo come oggetto html e poi plottarlo
- cambiare providers con uno più semplice
- evitare markers difficile

questa immagine sotto è troppo grande, occupa tutta una pagina del PDF
-->
<div class="figure">
<img src="images/map.png" alt="" />
<p class="caption">point referenced data example, Milan Rental Real Estate, Author’s Source</p>
</div>
<p>REST API seen in chapter <a href="Infrastructure.html#Infrastructure">3</a> extracts point referenced data, so modeling methodologies described in this analysis will exclusively take into account point referenced oriented techniques.
In order to extend the notion from discrete measurements (i.e. point referenced) to a continuous spatial surface a stochastic process, namely Gaussian Process, has to be introduced and constrained according to convenient properties. GP are then evaluated with a specific covariance function, i.e. Matèrn. The reason why Matérn is selected as candidate for covariance function will be much more clear in the next chapter <a href="spde.html#spde">6</a>.
Hedonic Price Models are at first introduced and then a brief literature review is offered. Hedonic Prices brings to this work the theoretical basis but they do not suggest estimation methods, which are essentially the major issue in geostatistics. For this reason Hedonic Models are exploited into a spatial bayesian regression framework with the aim to apply INLA (seen in chpater <a href="inla.html#inla">4</a>) methodology.
At first standard Bayesian regression is presented as introduction, then the spatial component in the form of a GP is added to the model. Many parameters are considered so far, as a consequence a hierarchy structure is imposed. To this extent an entire section is dedicated to hierarchy which simplifies model building and methodology understanding as well as allowing to bring in many different parameters that come from different levels through the exchangeability property.
As a matter of fact parameters originate from the Gaussian latent field, but also from Matérn covariance function tuning hyper parameters.
Then INLA is applied and a GMRF representation of GP is…
Spatial kriging is essential to predict the process at new locations so that the spatial surface can be plotted and analyzed.
In the end models have to be checked and verified with resampling schemes which are once again specific to the data type and the scope of the analysis.</p>
<p><em>(forse mettere alla fine come further developments)</em>
As a side note Spatial data can also be measured according to a further dimension which is the Time. Latest literature suggests that spatio temporal models are the most accurate, as a consequence it might be interesting to research time correlation between subsequent spatial data time points, a valuable reference is offered in <span class="citation">Paci et al. (<a href="#ref-PACI2017149" role="doc-biblioref">2017</a>)</span>. This will not take an enormous effort due ti the fact that on a daily basis REST API generates data which are stored as .json file on a DB. Future research on this data might consider the idea to include the time component in the model.</p>
<div id="GP" class="section level2">
<h2><span class="header-section-number">5.1</span> Gaussian Process (GP)</h2>
<p>For simplicity lets consider <span class="math inline">\(y\)</span> point of interest observations <span class="math inline">\(y\left(\boldsymbol{s}_{1}\right),y\left(\boldsymbol{s}_{2}\right), \ldots, y\left(\boldsymbol{s}_{n}\right)\)</span>
from a random spatial process <span class="math inline">\(Y\)</span>, such that: <span class="math inline">\(Y\left(\boldsymbol{s}_{1}\right),Y\left(\boldsymbol{s}_{2}\right), \ldots, Y\left(\boldsymbol{s}_{n}\right)\)</span> observed at location <span class="math inline">\(\boldsymbol{s}_{1}, \ldots, \boldsymbol{s}_{n}\)</span>. In the context of geostatistical data each observation has to be considered as a partial realization of an unobserved random spatial process.
<span class="math inline">\(\left\{Y(s): s \in D \subset \mathbb{R}^{2}\right\}\)</span>, where surface <span class="math inline">\(D\)</span> is a subset of r-dimensional Euclidean space <span class="math inline">\(\mathbb{R}^{r}\)</span>.
Moreover When <span class="math inline">\(r = 1\)</span> it is the most simple stochastic process widely explored in literature i.e. time series process. However geostatistical data always have <span class="math inline">\(r = 2\)</span> (i.e. lat and long, eastings and northings) or eventually <span class="math inline">\(r = 3\)</span>, when elevation data is available. The stochastic process <span class="math inline">\(Y\)</span> is observed in a fixed set of “monitoring stations” and inference can be done regarding moments of the realized process. This information are essential to build a spatially continuous surface over the y-studied variable in order to predict the phenomenon at locations not yet observed.</p>
<div class="figure">
<img src="images/prdprocess.png" alt="" />
<p class="caption">3D scatterplot and surface, Stockton data.</p>
</div>

<div class="definition">
<span id="def:GP" class="definition"><strong>Definition 5.1  (GP definition)  </strong></span>A collection of <span class="math inline">\(n\)</span> random variables, such as <span class="math inline">\(Y(s_{1}), Y(s_{2}) , \ldots, Y(s_{n})\)</span> that are <em>valid</em> spatial processes are said to be a <strong>GP</strong> if for any set of spatial index <span class="math inline">\(n\)</span> and for each set of corresponding locations <span class="math inline">\(\left\{y\left(s_{1}\right), \ldots, y\left(s_{n}\right)\right\}\)</span> follows a multivariate <em>Gaussian</em> distribution with mean <span class="math inline">\(\boldsymbol{\mu}=\left\{\mu\left(s_{1}\right), \ldots, \mu\left(s_{n}\right)\right\}\)</span> and covariance matrix <span class="math inline">\(\mathbf{Q}^{-1}_{i,j}, \forall i \neq j\)</span>
</div>

<p>Even tough sometimes it is more convenient to express the covariance matrix as its inverse i.e. precision matrix <span class="math inline">\(\boldsymbol{Q}_{i,j}\)</span> <span class="citation">(Marta Blangiardo <a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span>. The covariance matrix relates each observation to each of the others through a covariance function defined as <span class="math inline">\(\mathcal{C}(\cdot)\)</span>.</p>
<p>GP in the spatial context must check two important properties in order to exploit INLA, even though both of these assumptions can be relaxed:</p>
<ul>
<li><strong>Stationary</strong>.</li>
<li><strong>Isotropy</strong>.</li>
</ul>
<p><strong>Stationarity</strong> in a stochastic process can be <em>strong</em>, <em>weak</em> or <em>intrinsic</em>. The strong property forces the distribution of the process <span class="math inline">\(\left\{y\left(s_{1}\right), \ldots, y\left(s_{n}\right)\right\}\)</span> for any given spatial index <span class="math inline">\(n\)</span> and its correspondent location sets <span class="math inline">\(s_{1,\ldots,n}\)</span> to be the same as the one in <span class="math inline">\(\left\{y\left(s_{1}+\boldsymbol{h}\right), \ldots, y\left(s_{n}+\boldsymbol{h}\right)\right\}\)</span>, where <span class="math inline">\(h\)</span> is a number belonging to <span class="math inline">\(R^{2}\)</span>.
On the other hand the weak property ensures that if the GP mean moment is constant over the study domain <span class="math inline">\(\mu(\mathbf{s}) \equiv \mu\)</span> (e.g. <span class="math inline">\(E[Y(s)]=\mu, \forall s \in D\)</span>) then the covariance functions does depend only on the distance (euclidean <span class="math inline">\(\left\|s_{i}-s_{j}\right\|\)</span> distance) between each couple points.
Weak stationarity consequences are the most interesting: It does not matter whether observations are placed either in a specific region, nor the direction towards they are oriented, the covariance functions <span class="math inline">\(\mathcal{C}(h)\)</span> can summarize the process through the separation vector <span class="math inline">\(\mathbf{h}\)</span> i.e. <span class="math inline">\(\mathcal{C}(\mathbf{s}, \mathbf{s}+\mathbf{h})=\mathcal{C}(\mathbf{h}), \forall \mathbf{h} \in \mathbb{R}^{r}\)</span> <span class="citation">(Banerjee, Carlin, and Gelfand <a href="#ref-Banerjee-Gelfand" role="doc-biblioref">2014</a>)</span>. In other words weak stationarity in GP implies being invariant under <em>translation</em> <span class="citation">(<a href="#ref-Krainski-Rubio" role="doc-biblioref">2019</a>)</span>. The relationship between strong and weak is not bijective since being strong implies also being weak, but the opposite is not always true for non-Gaussian process.
Furthermore through the intrinsic stationary property it is meant that <span class="math inline">\(E[Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s})]=0\)</span>, the second moment of the latter expression can be written as <span class="math inline">\(E[Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s})]^{2}\)</span> leading to <span class="math inline">\(\operatorname{Var}(Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s}))\)</span>. Last expression is called <em>variogram</em> and can be expressed with <span class="math inline">\(2 \gamma(\mathbf{h})\)</span>, even tough its half,i.e. <span class="math inline">\(\gamma(\mathbf{h})\)</span>, is more interpretable, namely <em>semivariogram</em> <span class="citation">(Cressie <a href="#ref-Cressie_2015" role="doc-biblioref">2015</a>)</span>.</p>
<p>Semivariograms are characterized by mainly 3 tuning parameters:</p>
<ul>
<li><em>range</em> <span class="math inline">\(\sigma^{2}\)</span>: At some offset distance, the variogram values will stop changing and reach a sort of “plateau”. The distance at which the effect occurs is called the range <span class="math inline">\(\frac{\Delta\gamma(\mathrm{h})}{h} \approx 0\)</span>.</li>
<li><em>sill</em> <span class="math inline">\(\tau^{2}\)</span>: The “plateau” value at which the variogram stops changing <span class="math inline">\(\frac{\Delta\gamma(\mathrm{h})}{h} = 0\)</span>.</li>
<li><em>nugget</em> <span class="math inline">\(\tau^{2}+\sigma^{2}\)</span>: The discontinuity at the origin. Although this theoretically should be zero, sampling error and short scale variability can cause it to be non-zero <span class="math inline">\(\gamma(\mathrm{0})\)</span>.</li>
</ul>
<div class="figure">
<img src="images/variogram.PNG" alt="" />
<p class="caption">variogram example</p>
</div>
<p>presi i dati con le relative distanze euclidee a coppie di punti si binnano le distanze grazie ad un offset ottenendo i valori per il semivariogram. ottenuti i valori si fitta il semivargiogram a quei valori, un modo è la likelihood. A questo punto si calcolano le tre grandezze nugget sill e range per poi poter far uscire le funzioni di covarianza.</p>
<!-- <!-- non so se tenere -->
<!-- da qui -->
<!-- -->
<!-- Furthermore since it is assumed to be true by the intrinsic stationary property that $E[Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s})]=0$, the second moment of the latter expression can be written as $E[Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s})]^{2}$ leading to $\operatorname{Var}(Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s}))$. Last expression is called _variogram_ and can be expressed with $2 \gamma(\mathbf{h})$, even tough its half,i.e. $\gamma(\mathbf{h})$, is more interpretable, namely _semivariogram_ [@Cressie_2015]. -->
<!-- The intuition behind the variogram is that the difference in value between two near points $Y(\mathbf{s}+\mathbf{h})$ and $Y(\mathbf{h})$ is expected to be small with respect to the ones farther ( _ergodicity_ of the spatial process  @Banerjee-Gelfand ), in compliance with the first law of geography by Tobler:  -->
<!-- > "Everything is related to everything else,  -->
<!-- > but near things are more related than distant things" -->
<!-- > -->
<!-- >  <footer>--- Waldo R. Tobler</footer> -->
<!-- Semivariograms are an efficient tool to asses spatial continuity and contiguity but they are theoretical. However semivariograms can be fitted into existing data giving birth to empirical semivariograms which are then plotted against their separation vector. The plot can be used to verify the null hypothesis of spatial independence and variability of the process. The below expression is the empirical semivariogram functional form: -->
<!-- $$\hat{\gamma}(t)=\frac{1}{2}|N(t)| \sum_{\left(\mathbf{s}_{i}, \mathbf{s}_{j}\right) \in N(t)}\left(Y\left(\mathbf{s}_{i}\right)-Y\left(\mathbf{s}_{j}\right)\right)^{2}$$ -->
<!-- where $N(t)$ is the set of location pairs such that $\left\|\mathbf{s}_{i}-\mathbf{s}_{j}\right\|=t$ and so $|N(t)|$ is the number of pairs in the set. As already guessed before empirical semivariogram values are expected to be small at short pairs distance and tends to increase when distance increases. The rational behind is that similar observations are expected to lay close together (small $h$) leading to lower semivariogram values ($\gamma(\mathbf{h})$), as opposite farther pairs obervations (big $h$) tend to be different and associated to greater semivariogram values. Flat semivariogram might indicate small spatial variance, since whether separation $h$ increases or not, semivariogram values remains the same $\frac{\Delta\gamma(\mathbf{h})}{\Delta\mathbf{h}}\approx0$. Semivariograms might be implied earlier in the modeling process to to evaluate the presence of any spatial pattern. Then they are also implied in the model checking stage with the aim to asses if any spatial pattern is still present in the residuals.  -->
<!-- ![variogram example](images/variogram.png) -->
<!-- <!-- a qui -->
<p>The process is said to be <strong>Isotropic</strong> if the covariance function depends only on the between-points distance <span class="math inline">\(\left\|\mathbf{h}\right\|\)</span> so it is invariant under <em>rotation</em> <span class="citation">(<a href="#ref-Krainski-Rubio" role="doc-biblioref">2019</a>)</span>. A further way of seeing the property is that Isotropy implies concentric decaying contours that resemble the vanishing of spatial dependence, and so covariance values too.
then if the last assumption does not hold and direction towards point are distant from each other matters within the spatial domain <span class="math inline">\(D\)</span>, then is said to be <strong>Anisotropic</strong>.
Formalizing the results:</p>
<p><span class="math display">\[\mathcal{C}(\mathbf{h})=\mathcal{C}(\|\mathbf{h}\|)\]</span></p>
<div class="figure">
<img src="images/isotropyVSanisotropy.png" alt="" />
<p class="caption">isotropy VS anisotropy, source <span class="citation">Blanchet-Scalliet et al. (<a href="#ref-blanchetscalliet" role="doc-biblioref">2019</a>)</span></p>
</div>
</div>
<div id="spatial-covariance-function" class="section level2">
<h2><span class="header-section-number">5.2</span> Spatial Covariance Function</h2>
<p>The covariance function <span class="math inline">\(\mathcal{C}(\cdot)\)</span> ensures that all the values that are close together in input space will produce output values that are close together. <span class="math inline">\(\mathcal{C}(\cdot)\)</span> needs to inherits the <em>validity</em> characteristics from the random spatial process, furthermore it has to be <em>positive definite</em>.
In addition covariance function must share characteristic properties of functions, such as:</p>
<p>(cerca di capire queste…)</p>
<ul>
<li>Multiply valid covariance functions (summing independent random variables)</li>
<li>Mixing covariance functions (mixing distributions)</li>
<li>Convolving covariance functions, this will be very important …</li>
</ul>
<!-- Below a generalized version for two random $i$th $j$th observations: -->
<!-- \begin{equation} -->
<!-- \operatorname{Cov}\left(y\left(s_{i}\right), y\left(s_{j}\right)\right) -->
<!-- (\#eq:cov) -->
<!-- \end{equation} -->
<p>Covariance functions under stationary and isotropic GPs displays two important properties: they are constant in mean within <span class="math inline">\(D\)</span> i.e. <span class="math inline">\(\mathcal{C}(\mathbf{s}, \mathbf{s}+\mathbf{h})=\mathcal{C}(\mathbf{h}), \forall \mathbf{h} \in \mathbb{R}^{r}\)</span> and they depends on distance vector <span class="math inline">\(\mathbf{h}\)</span>, not direction i.e. <span class="math inline">\(\mathcal{C}(\mathbf{h})=\mathcal{C}(\|\mathbf{h}\|)\)</span>
There are many covariance functions and ways to relate distant points on a spatial domain <span class="math inline">\(D\)</span>. Typically the choice of the Covariance can depend either on data or the scope of the analysis. Covariance functions are wrapped into special hyper parameters which are mainly three:</p>
<ol style="list-style-type: decimal">
<li><em>Range</em>: At some offset distance, the variogram values will stop changing and reach a “plateau”. The distance at which this occurs is called the range.</li>
<li><em>Sill</em>: The “plateau” value at which the variogram stops changing.</li>
<li><em>Nugget</em>: The discontinuity at the origin. Although this theoretically should be zero, sampling error and short scale variability can cause it to be non-zero</li>
</ol>
<p>(espressione della covariance function insieme a alle <span class="math inline">\(\sigma^2\)</span> come: <span class="math inline">\(C(\mathbf{s}+\mathbf{h}, \mathbf{s} \mid \theta)=\sigma^{2} \mathbf{R}(\|h\| ; \phi)\)</span>)
spiega anche queste due sotto</p>
<p><span class="math display">\[
\mathbf{w}=\left(w\left(\mathbf{s}_{1}\right), \ldots, w\left(\mathbf{s}_{n}\right)\right)^{\prime} \sim \mathrm{N}\left(\mathbf{0}, \sigma^{2} \mathbf{R}(\phi)\right) \text { where } \left.\mathbf{R}(\phi)_{i j}=\rho\left(\left\|\mathbf{s}_{i}-\mathbf{s}_{j}\right\| ; \phi\right)\right)
\]</span></p>
<p><span class="math inline">\(\Sigma_{\theta}=\sigma^{2} \mathbf{R}(\phi)+\tau^{2} I_{n}\)</span></p>
<p>A summary of the most used covariance functions are presented below.</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text { Exponential } \quad \mathcal{C}(\mathbf{h})=\left\{\begin{array}{cl}
\tau^{2}+\sigma^{2} &amp; \text { if }  h=0 \\
\sigma^{2} \exp (-\phi h) &amp; \text { if } h&gt;0 
\end{array}\right.\\
&amp;\text { Gaussian } \quad \mathcal{C}(\mathbf{h})=\left\{\begin{array}{cl}
\tau^{2}+\sigma^{2} &amp; \text { if } h=0 \\
\sigma^{2} \exp \left(-\phi^{2} h^{2}\right) &amp; \text { if } h&gt;0 
\end{array}\right. \\
&amp;\text { Matérn } \quad \mathcal{C}(\mathbf{h})=\left\{\begin{array}{cl}
\tau^{2}+\sigma^{2} &amp; \text { if } h=0 \\
\frac{\sigma^{2}}{2^{\nu-1} \Gamma(\nu)}(\phi h)^{\nu} K_{\nu}(\phi h) &amp; \text { if } h&gt;0
\end{array}\right.
\end{aligned}
\]</span></p>
<div id="Matern" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Matérn Covariance Function</h3>
<p>Matérn is special since when it is used together with a stationary and isotropic GP, the SPDE approach can provide a GMRF representation of the same process, chapter <a href="spde.html#spde">6</a> discloses this fundamental property.
Matérn can also be accounted as the most used in geostatistics <span class="citation">(Krainski et al. <a href="#ref-Krainski2018" role="doc-biblioref">2018</a>)</span> and <span class="citation">(Gómez Rubio <a href="#ref-Bayesian_INLA_Rubio" role="doc-biblioref">2020</a>)</span> and is tuned mainly by two parameters, a scaling one <span class="math inline">\(\kappa&gt;0\)</span>, usually set equal to the range by the relation <span class="math inline">\(\sigma^{2}=\frac{\sqrt{8 \lambda}}{\kappa}\)</span>) and a smoothing one <span class="math inline">\(\nu&gt;0\)</span>. A <em>stationary</em> and <em>isotropic</em> Matérn covariance function has this form:</p>
<p><span class="math display">\[
\mathcal{C}(\mathbf{h})=\left\{\begin{array}{ll}
\tau^{2}+\sigma^{2} &amp; \text { if } h=0 \\
\frac{\sigma^{2}}{2^{\nu-1} \Gamma(\nu)}(\phi t)^{\nu} K_{\nu}(\phi t) &amp; \text { if } h&gt;0
\end{array}\right.
\]</span></p>
<p><span class="math inline">\(\Gamma(\nu)\)</span> is a Gamma function depending on <span class="math inline">\(\nu\)</span> values, <span class="math inline">\(K_{\nu}(\cdot)\)</span> is a modified Bessel function of second kind. The smoothness parameter <span class="math inline">\(\nu\)</span> in the figure below takes 4 different values showing the potentiality of Matérn to relates distances to covariance values. When <span class="math inline">\(\nu = 1\)</span> … When <span class="math inline">\(\nu = 1/2\)</span> it becomes the exponential covariance function, When <span class="math inline">\(\nu = 3/2\)</span> it uncovers a convenient closed form, when <span class="math inline">\(\nu \approx \infty\)</span>, in this case for representation purposes <span class="math inline">\(\nu = 80\)</span> it becomes Gaussian covariance function.</p>
<div class="figure">
<img src="images/matern.png" alt="" />
<p class="caption">matern correlation function for 4 diff values of nu with phi fixed, author’s source</p>
</div>
<p>ancora di più su matern, forse di più in spde</p>
<!-- By decomposing it into a more granular form and cosidering two generic locations $\mathbf{S}_{i}$  and $\mathbf{S}_{j}$, -->
<!-- $$ -->
<!-- \operatorname{Cor}_{Matérn}\left(U\left(\mathbf{s}_{i}\right), U\left(\mathbf{s}_{j}\right)\right)=\frac{2^{1-\nu}}{\Gamma(\nu)}\left(\kappa\left\|\mathbf{s}_{i}-\mathbf{s}_{j}\right\|\right)^{\nu} K_{\nu}\left(\kappa\left\|\mathbf{s}_{i}-\mathbf{s}_{j}\right\|\right) -->
<!-- $$ -->
<!-- where $\|\cdot\|$ is the Euclidean distance, $\Gamma(\cdot)$ is a gamma function and $K_{\nu}(\cdot)$ is a modified Bessel function of second kind. The relationship that ties Matérn correlation and covariance is $\mathcal{C}(h_{i,j}) = \operatorname{Cov}_{Matérn}\left(U\left(\mathrm{s}_{i}\right), U\left(\mathrm{s}_{j}\right)\right) = \sigma_{u}^{2} \operatorname{Cor}_{M}\left(U\left(\mathbf{s}_{i}\right), U\left(\mathbf{s}_{j}\right)\right)$. -->
<!-- Then if $u(\mathbf{s})$ is a realization from $U(\mathbf{s})$ at $n$ locations the joint covariance matrix can be defined as each entry of the joint covariance matrix $\Sigma_{i, j}= \sigma_{u}^{2} \operatorname{Cor}_{M}\left(U\left(\mathbf{s}_{i}\right), U\left(\mathbf{s}_{j}\right)\right)$. Common customary choice is to assume that $U(.)$ in centered in 0. -->
</div>
</div>
<div id="hedonic-models-literature-review-and-spatial-hedonic-price-models" class="section level2">
<h2><span class="header-section-number">5.3</span> Hedonic models Literature Review and Spatial Hedonic Price Models</h2>
<p>The theoretical foundation of the Hedonic Price Models (from now on HPM) resides in the consumer utility theory of <span class="citation">Lancaster (<a href="#ref-Lancaster" role="doc-biblioref">1966</a>)</span> together with <span class="citation">Rosen (<a href="#ref-Rosen" role="doc-biblioref">1974</a>)</span> market equilibrium. According to Lancaster the utility of a commodity does not exist by itself, instead it exists as the sum of the utilities associated to its separable characteristics. Integrating Lancater, Rosen introduces HPM and suggests that each separate commodity characteristics are priced by the markets on the basis of supply and demand equilibrium. Applying HPM to Real Estate in a market context, from the buy side house prices (but also rents) are set as the unit cost of each household attributes, conversely from the selling side the expenditures associated to build of each them.
Formalizing the results, Hedonic Price <span class="math inline">\(P\)</span> in Real Estate is expressed as a general <span class="math inline">\(f\)</span> functional form that takes as input the house characteristics vector <span class="math inline">\(\mathbf{C}\)</span>.</p>
<p><span class="math display">\[P=f\left(c_{1}, c_{2}, c_{3}, \ldots, c_{n}\right)\]</span></p>
<p>Vector <span class="math inline">\(\mathbf{C}\)</span> since now might contain a unidentified and presumably vast number of ungrouped characteristics. In this setting <span class="citation">Malpezzi (<a href="#ref-Malpezzi" role="doc-biblioref">2008</a>)</span> tried to organize house features by decomposing <span class="math inline">\(\mathbf{C}\)</span> into mutually exclusive and exhaustive subgroups. An overview of the vector components involved is given by <span class="citation">Ling and Ling (<a href="#ref-Ling" role="doc-biblioref">2019</a>)</span> according to which <span class="math inline">\(P\)</span> represents the house price, <span class="math inline">\(S\)</span> is the structural characteristics of the house, <span class="math inline">\(N\)</span> represents the neighborhood characteristics, <span class="math inline">\(L\)</span> signifies the locational characteristics, <span class="math inline">\(C\)</span> describes the contract conditions and <span class="math inline">\(T\)</span> is time. <span class="math inline">\(\beta\)</span> is the vector of the parameters to be estimated. Then</p>
<p><span class="math display">\[P=f\left(S, N, L, C, T, \beta\right)\]</span></p>
<p>Historically a first attempt to include spatial effect in urban economic literature is provided by <em>Alonso (1964) miss ref</em>. Its contribution was to raise voice on house prices (also rent) mainly depending on land price and a number of purely spatial covariates like CBD, the distance from City Business District. Other covariates were transport cost per kilometer and community income, even though they were defined also as spatial parameters through distances. The model proposed by Alonso is called monocentric since the centroid from which distances are calculated is only one. Moreover a first touch to spatial data thory was done since the CBD was defined as areal unit with well-defined boundaries of regular or irregular shape. However applications of the model were not convincing since empirical studies offered a different picture. Results instead displayed a Poly-centric areal structure (universities and Malls) which might be better explaining prices. The model also assumed that covariates like CBD are only informative within city center boundaries and then displayed no significance out of the core of the city. Poly-centric theory was also more coherent with the architectural and socio-economical evolution of cities during that times, therefore mono centric theory was then criticized and abandoned. Critics regarded also neighborhood quality measure and boundary problems <em>Dubin (1987) miss ref</em>. Dubin for these reasons developed a model including areal effects in the error term since handling these covariates was posing several hard challenges. Areal data choice for Dubin was forced since he was interested in land values, geostatics interest was not a focus also due to the difficulties in gathering accurate data. Coming to recent literature a change in focus has been made by switching from theory based model to estimation methods. As a consequence to the change in focus <span class="citation">Ling and Ling (<a href="#ref-Ling" role="doc-biblioref">2019</a>)</span> said that practitioners should spend more time in variable selection and model specification with respect to their specific need.
As Ling has observed the emerging trends are in the field of semi-parametric and non-parametric methods <span class="citation">(<a href="#ref-Ling" role="doc-biblioref">2019</a>)</span>. Historically semi-parametric regression considers models indexed by spatial coordinates <em>Pace RK (1995)</em>. At the same time <em>Kammann and Wand (2003)</em> gave birth to geoadditive models where the spatial component is added as a covariate. […]</p>
<p>A further aspect of the problem is posed by scholars that do not consider rents to be representative for the actual value of real estate. Nevertheless in empirical analysis rent value are considered a proxy for real estate pricing <span class="citation">(Herath and Maier <a href="#ref-Herath_Maier_2011" role="doc-biblioref">2011</a>)</span>. A further argument to endorse this hypothesis is brought by <span class="citation">Manganelli, Morano, and Tajani (<a href="#ref-sellingVSrental" role="doc-biblioref">2013</a>)</span> considering housing a commodity, then the selling or the rental should be considered interchangeable economic actions with respect to same inner need to be satisfied. This is also truer to the thesis’ extent since Manganelli, Morano, and Tajani have centered their analysis exactly on italian real estate data. Moreover <span class="citation">Capozza and Seguin (<a href="#ref-Capozza_Seguin_1996" role="doc-biblioref">1996</a>)</span> discussed on how much rent-price ratio predicts future changes both in rents and prices. Among all the other discussions raised they brought the decomposition of rent-price ratio into two parts: the predictable part and the unexplained residuals part. The predictable part was discovered to be negatively correlated with price changes, in other words cities in which prices are relatively high with respect to rents are associated with higher capital gains that might justify that misalignment. This is also true for the opposite, that is cities in which prices are lower with respect to the rents, and this effect can not be associated to any local condition, realize lower capital gains. A further argument is offered by Clark <span class="citation">(Clark <a href="#ref-Clark_1995" role="doc-biblioref">1995</a>)</span> which went after the Capozza and Seguin work. Rent-price ratio is negatively correlated with following future changes in rents. In other words prices are still higher when areas in which they are observed documents an increase in rent prices. All the literature review above is oriented to a long-run alignment of price and rent.</p>
</div>
<div id="univariateregr" class="section level2">
<h2><span class="header-section-number">5.4</span> Point Referenced Regression for univariate spatial data</h2>
<p>Since in HPM the relationships between the characteristics of the house, i.e. vector <span class="math inline">\(\mathbf{C}\)</span> and the price <span class="math inline">\(P\)</span> is not in any case fixed by econometric literature it is possible to assume any <span class="math inline">\(f\)</span> functional form. The open possibility to apply a wide range of relationship between covariates fit in the INLA setting, since Latent Gaussian Models are prepared to accept a any linear and non linear <span class="math inline">\(f\)</span> functions <a href="inla.html#LGM">4.1</a> through the <code>f()</code> method. Hedonic price models are, as a consequence, a subset of models that can be fitted into LGM and therefore by INLA method.</p>
<p>Moreover what the vast majority of econometric literature <em>(Greene, 2018)</em> suggest to apply a is log-linear / square root model. This is due to the fact that log transformation / square root smooths the skewness of prices normalizing the curve, leading to more accurate estimates. Having an exponential family generating process lowers even further computational cost for reasons linked to the <span class="math inline">\(\tilde\pi(\boldsymbol{\psi})\)</span> hyper param INLA approximation <span class="citation">(Marta Blangiardo <a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span>. Notation is taken from the previous chapter <a href="inla.html#inla">4</a>, for brevity purposes <span class="math inline">\(\boldsymbol{\beta}\)</span> <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\boldsymbol{y}\)</span> indicates vectors incorporating all their respective realizations and the <span class="math inline">\(s\)</span> spatial component is left out in favor of the observation pedix <span class="math inline">\(i\)</span>.<br />
The simplest log-linear bayesian regression model assumes linear relationship between predictors and a Normal data generating process: (log has been taken out for simplicity, bu it will be then considered in the regression setting) (valuta l’idea che per interpretabilità di modellarla come Gamma exponential family anzichè tenerla normale)</p>
<p><span class="math display">\[
\log{(y_{i})} \sim \operatorname{Normal}(\mu_{i}, \sigma^{2})
\]</span></p>
<p><span class="math display">\[
y_{i}=\mu_{i}+\varepsilon_{i}
\]</span></p>
<p>then by the following relationship <span class="math inline">\(E\left(y_{i} \mid \beta_{0}, \ldots, \beta_{M}, x_{i 1}, \ldots, x_{i M}\right)=\beta_{0}+\sum_{m=1}^{M} \beta_{m} x_{i m}\)</span> it is possible to specify a more general linear predictor (seen also in chapter <a href="inla.html#inla">4</a>) through an identity link function i.e. <span class="math inline">\(\eta_{i}=g\left(\mu_{i}\right)=\mu_{i}\)</span> obtaining:</p>
<p><span class="math display">\[
\eta_{i}=\beta_{0}+\sum_{m=1}^{M} \beta_{m} x_{m i}+\sum_{l=1}^{L} f_{l}\left(z_{l i}\right)
\]</span></p>
<p>Where, once again, the mean structure linearly depends on some <span class="math inline">\(\mathbf{X}\)</span> covariates, <span class="math inline">\(\boldsymbol{\beta}\)</span> coefficients, <span class="math inline">\(f_{l}(\cdot), \forall l \in 1 \ldots L\)</span> are a set of random effects defined in terms of a <span class="math inline">\(\boldsymbol{z}\)</span> set of covariates <span class="math inline">\(\boldsymbol{z}=\left(z_{1}, \ldots, z_{L}\right)\)</span> (e.g. rw, ar1) and <span class="math inline">\(\varepsilon_{i}\)</span> white noise error.
Priors have to be specified and a non informativeness for <span class="math inline">\(\tau^2 = 1/\sigma^2\)</span> and <span class="math inline">\(\boldsymbol{\beta}\)</span> is chosen, such that <span class="math inline">\(\pi(\tau^2) \propto 1\)</span> and <span class="math inline">\(\pi(\boldsymbol\beta) \propto 1\)</span>. As a consequence the conditional posterior for the parameters of interest <span class="math inline">\(\boldsymbol{\beta}\)</span> is:</p>
<p><span class="math display">\[
\boldsymbol{\beta} \mid \sigma^{2}, \boldsymbol{y}, \boldsymbol{X} \sim \operatorname{MVNormal}\left(\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{y}, \sigma^{2}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1}\right)
\]</span></p>
<p>where the mean structure corresponds to the OLS estimator: <span class="math inline">\(\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{y}\)</span> for <span class="math inline">\(\beta\)</span> and then to obtain the marginal posterior for <span class="math inline">\(\boldsymbol{\beta}\)</span> it is needed to integrate with respect to <span class="math inline">\(\sigma^2\)</span>.</p>
<p>In order to engage the spatial coordinate components into the regression setting <span class="math inline">\(w_{i}\)</span> has to be added to the equation. <span class="math inline">\(w_{i}\)</span> is set as a stationary and isotropic GP with mean 0 and variance as covariance function expressed as Matérn.
Recall that GP
The new regression setting integrates the <em>spatial error</em> part in the name of <span class="math inline">\(w_{i}\)</span> and a <em>non-spatial error</em> part <span class="math inline">\(\varepsilon_{i}\)</span> distributed normally with mean 0 and variance <span class="math inline">\(\tau^2\)</span> ,i.e. <span class="math inline">\(\mathrm{N}\left(0, \tau^{2}\right)\)</span>, which offers its contribution error to the nuggets via the covariance function.
Consequently there is one more parameter to estimate. It is worth mentioning that the distribution of <span class="math inline">\(w_{i}\)</span> at a finite number of points is considered a realization of a multivariate Gaussian distribution. In this case, the likelihood estimation is possible and it is the multivariate Gaussian distribution with covariance <span class="math inline">\(\Sigma\)</span>.</p>
<p><span class="math display">\[
\log(y_{i})= \beta_{0} + (\mathbf{X})^{\prime}\boldsymbol{\beta}+w_{i}+\varepsilon_{i}
\]</span></p>
<p>The covariance of the marginal distribution of <span class="math inline">\(y_{i}\)</span> at a finite number of locations is <span class="math inline">\(\Sigma_{y} = \Sigma + \tau^2\mathbf{I}\)</span>, where <span class="math inline">\(\mathbf{I}\)</span> denotes the indicator function (i.e., <span class="math inline">\(\mathbf{I}(i = i^{\prime})= 1\)</span> if <span class="math inline">\(i = i^{\prime}\)</span>, and 0 otherwise). This is a short extension of the basic GF model, and gives one additional parameter to estimate</p>
<!-- \begin{equation} -->
<!--     \log(y_{i})=\mu_{i}+\varepsilon_{i} -->
<!-- (\#eq:genreg) -->
<!-- \end{equation} -->
<!-- where $y_{i}$ is normally distributed as $y_{i} \sim \operatorname{Normal}\left(\mu_{i}, \sigma^{2}\right)$ and $\mu_{i}$ is the mean structure that linearly depends on some $\mathbf{X}$ covariates, $\boldsymbol{\beta}$ coefficients, $f_{l}(\cdot), \forall l \in 1 \ldots L$ are a set of random effects defined in terms of a $\boldsymbol{z}$ set of covariates $\boldsymbol{z}=\left(z_{1}, \ldots, z_{L}\right)$ (e.g. rw, ar1) and  $\varepsilon_{i}$ white noise error. Please recall that the $i$th pedices are the observations and the $m$th pedices are the covariates. The structure is a repetition of what already seen in chapter \@ref(LGM) -->
<!-- \begin{equation} -->
<!--   \eta_{i}=\beta_{0}+\sum_{m=1}^{M} \beta_{m} x_{m i}+\sum_{l=1}^{L} f_{l}\left(z_{l i}\right) -->
<!-- (\#eq:linearpred) -->
<!-- \end{equation} -->
<!-- The link function specified in this case is still identity, so that $\eta_{i}=g\left(\mu_{i}\right)=\mu_{i}$. Nevertheless GLMs can be applied with different link function. when response variable has to stay between $[0,1]$ (e.g. probabilities), the link function might be Logit, which leads to logistic regression. More generally expressed in vector notation: -->
<!-- \begin{equation} -->
<!--   \log(y_{i})\left(\mathbf{s}_{i}\right)=\mathbf{x}\left(\mathbf{s}_{i}\right)^{\prime} \beta_{j}+\varepsilon\left(\mathbf{s}_{i}\right) -->
<!--   (\#eq:genregvec) -->
<!-- \end{equation} -->
<!-- where its OLS estimator is: -->
<!-- \begin{equation} -->
<!--   \hat{\beta}=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{y} -->
<!-- (\#eq:ols) -->
<!-- \end{equation} -->
<!-- Moreover In the context of bayesian analysis a prior distribution has to be imposed on the regression coefficients $\beta = \left\{\beta_{0}, \ldots, \beta_{J}\right\}$ as well ad on the variance  $\sigma^{2}$ of $y_{i}$. When no expert information is provided vague priors are introduced, meaning that the regression should not be weighted too much on the priors choice. -->
<!-- Vague priors might be: -->
<!-- - $\beta_{m} \sim \operatorname{Normal}\left(0,10^{6}\right)$ for the beta coefficients -->
<!-- - $\log (\tau)=\log \left(1 / \sigma^{2}\right) \sim \log \operatorname{Gamma}\left(1,10^{-5}\right)$ for precision -->
<!-- Spatial modeling goal is to include spatial information from location into the model. This is done within the bayesian frameoùwork and INLA by adding $w(\mathbf{s})$ in the previous equation \@ref(eq:genregvec).  -->
<!-- $$y\left(\mathbf{s}_{i}\right)=\mathbf{x}\left(\mathbf{s}_{i}\right)^{\prime}\beta_{j}+w(\mathbf{s})+\varepsilon\left(\mathbf{s}_{i}\right)$$ -->
<!-- The $w(\mathbf{s})$ in the context of the analysis is approached as a stationary and isotropic GP\@ref(GP) whose distribution by definition is multivariate Gaussian with mean $\boldsymbol{\mu}(\mathbf{s}) = 0$ and function of the spatial index $\mathbf{s}$ and covariance function $\mathcal{C}( \cdot \mid \theta)$ . -->
<!-- $\varepsilon(\mathbf{s})$ is iid and mean centered in 0 with variance $\tau^{2}$ and is called non-spatial error since it contributes to the nugget. The error term is pure since it interferes with the covariance function so that the model can embody the spatial component.  -->
<!-- One of the major advantages of having a a spatial process embedded into a GP is _likelihood_ based inference.  -->
<!-- ### Parameter estimation  -->
<!-- Gaussian spatial models can be considered as GLM with a particular specification of the precision matrix $\Sigma_{\theta}=\sigma^{2} \mathbf{R}(\phi)+\tau^{2} I_{n}$, -->
<!-- then the likelihood can be computed by: -->
<!-- $$\mathbf{y} \mid \boldsymbol{\theta}, \boldsymbol{\beta} \sim \mathrm{N}\left(\mathbf{X} \beta, Q_{\theta}\right)$$ -->
<!-- where,  $\boldsymbol{\theta}=\left(\sigma^{2}, \tau^{2}, \phi\right)$ -->
<!-- Since likelihood estimation is possible then MLE can be computed for $\boldsymbol{\beta}$ and $\boldsymbol{\theta}$ are $\hat{\boldsymbol{\beta}}$ and $\hat{\boldsymbol{\theta}}$.  -->
<!-- Then the estimation in vector notation is:  -->
<!-- $$\hat{\boldsymbol{\beta}}_{M L E}=\left(\mathbf{X}^{\prime} Q^{-1} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} Q^{-1} \mathbf{y}$$ -->
</div>
<div id="hiermod" class="section level2">
<h2><span class="header-section-number">5.5</span> Hierarchical Bayesian models</h2>
<p>Spatial Models are characterized by many parameters which in turn are tuned by other hyper-parameters. Traditionally Bayesian hierarchical models are not widely adopted since they have high computational burdens, indeed they can handle very complex interactions via random components, especially when dealing with spatio temporal data <span class="citation">Ling and Ling (<a href="#ref-Ling" role="doc-biblioref">2019</a>)</span>. Blangiardo e Cameletti <span class="citation">(<a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span> tried to approach the problem from a different angle offering an intuitive solution on how hierarchy relates different levels parameters. This is done by reversing the problem and starting from data back to parameters, instead the other way round. So taking a few steps back the problem can be reformulated by starting from grouping observation into categories and then trying to impose a hierarchical structure on data based on the categories. As a result observations might fall into different categories, underlining their natural characteristics, such as: some of them might belong to category <em>levels</em> like males or females, married or not-married. Moreover diving into the specific problem house prices can be faceted by which floor they belong or whether they are assigned to different energy classes and many others more. As an example Blangiardo and Cameletti example consider grouping data according to just a single 9 <em>levels</em> category. Data for the reasons stated before can be organized such that each single observation (squares in figure below) belongs to its respective mutually exclusive and collectively exhaustive category (circles in figure).</p>
<div class="figure">
<img src="images/simple.PNG" alt="" />
<p class="caption">9 levels cat vs observaitions, source <span class="citation">Marta Blangiardo (<a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span></p>
</div>
<p>Furthermore data can be partitioned into two meta-categories, <em>fist level</em> and <em>second level</em>, highlighting the parameter and hyper paramter chain roles. <em>First level</em> are identified by sampling observations which are drawn by the same probability distribution (squares) . <em>Second level</em> (circles) are categories and might be associated to a set of parameters <span class="math inline">\(\theta=\left\{\theta_{1}, \ldots, \theta_{J}\right\}\)</span>.
Since the structure is hierarchical, a DAG (Directed Acyclical Graph) <span class="citation">(<a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span> representation might sort out ideas. If categories are represented by different <span class="math inline">\(\theta_{j}\)</span> nodes and edges (arrows in the figure) are the logical belonging condition to the category then a single parameter <span class="math inline">\(\theta\)</span> model has the right figure form:</p>
<p><img src="images/thetas.PNG" alt="DAG representation of hierarchical structure, source Marta Blangiardo (2015)" /> <img src="images/chis.PNG" alt="chis, Blangiardo-Cameletti’s source" /></p>
<p>To fully take into account the hierarchical structure of the data the model should also consider further lelvels. Since <span class="math inline">\(\left\{\theta_{1}, \ldots, \theta_{J}\right\}\)</span> are assumed to come from the same distribution <span class="math inline">\(\pi(\theta_{j})\)</span>, then they are also assumed to be sharing information <span class="citation">(Marta Blangiardo <a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span>, (left figure). When a further parameter <span class="math inline">\(\boldsymbol{\psi}=\left\{\psi_{1}, \ldots, \psi_{K}\right\}\)</span> is introduced, for which a prior distribution is specified, then the conditional distribution of <span class="math inline">\(\boldsymbol{\theta}\)</span> given <span class="math inline">\(\boldsymbol{\psi}\)</span> is:</p>
<p><span class="math display">\[
\pi\left(\theta_{1}, \ldots, \theta_{J} \mid \boldsymbol{\psi}\right)=\int \prod_{j=1}^{J} \pi\left(\theta_{j} \mid \psi\right) \pi(\psi) \mathrm{d} \psi
\]</span>
This is possible thanks to the conditional independence property already encountered in chapter <a href="inla.html#inla">4</a>, which means that each single <span class="math inline">\(\theta\)</span> is conditional independent given <span class="math inline">\(\psi\)</span>
This structure can extended to allow more than two levels of hierarchy since the marginal prior distributions of <span class="math inline">\(\theta\)</span> can be decomposed into the product of their conditional priors distributions given some hyper parameter <span class="math inline">\(\psi\)</span> as well as their prior distribution <span class="math inline">\(\pi(\psi)\)</span>.</p>
<p><span class="math display">\[
\pi(\boldsymbol{\theta})=\int \pi\left(\boldsymbol{\theta} \mid \boldsymbol{\psi}_{1}\right) \pi\left(\boldsymbol{\psi}_{1} \mid \boldsymbol{\psi}_{2}\right) \ldots \pi\left(\boldsymbol{\psi}_{L-1} \mid \boldsymbol{\psi}_{L}\right) \pi\left(\boldsymbol{\psi}_{L}\right) \mathrm{d} \boldsymbol{\psi}_{1} \ldots \mathrm{d} \boldsymbol{\psi}_{L}
\]</span></p>
<p><span class="math inline">\(\boldsymbol{\psi}_{l}\)</span> identifies the hyper pram for the <span class="math inline">\(l_{th}\)</span> level of hierarchy. Each further parameter level <span class="math inline">\(\psi\)</span> is conditioned to its previous in hierarchy level <span class="math inline">\(l-1\)</span> so that the parameter hierarchy chain is respected and all the linear combinations of parameters are carefully evaluated. The <em>Exchangeability</em> property enables to have higher <span class="math inline">\(H\)</span> nested DAG (i.e. add further <span class="math inline">\(L\)</span> levels) and to extend the dimensions in which the problem is evaluated, considering also time together with space. From a theoretical point of view there are no constraints to how many <span class="math inline">\(L\)</span> levels can be included in the model, but as a drawback the more the model is nested the more it suffers in terms of interpretability and computational power. Empirical studies have suggest that three levels are the desired amount since they offer a good bias vs variance trade-off.</p>
</div>
<div id="finalregr" class="section level2">
<h2><span class="header-section-number">5.6</span> INLA model through spatial hierarchical regression</h2>
<p>INLA model seen in section <a href="inla.html#LGM">4.1</a> can be rearranged according to the hierarchical structure considering also the regression settings for point referenced data stated in the previous section <a href="prdm.html#univariateregr">5.4</a>.</p>
<p>As an initial step it is required to specify a probability distribution for <span class="math inline">\(\boldsymbol{y} = \left(y\left(s_{1}\right), \ldots, y\left(s_{n}\right)\right)=\left(y_{1}, \ldots, y_{n}\right)\)</span>, this is a mandatory step looking at the <a href="inla.html#example">4.3.2</a> methods needed to compute the <code>inla()</code> function. A Normal distribution for simplicity is chosen.</p>
<p>As <em>first level</em> is picked up an <strong>exponential family</strong> sampling distribution (i.e. Normally distributed, Gamma one other choice), which is <em>exchangeable</em> with respect to the <span class="math inline">\(\boldsymbol{\theta}=\left\{\beta_{0}, \boldsymbol{\beta}, f\right\}\)</span> <em>latent field</em> and hyper parameters <span class="math inline">\(\boldsymbol{\psi_{1}}\)</span>, which includes also the ones coming from the latent Matérn GP process <span class="math inline">\(w_{i}\)</span>. The Spatial Guassian Process is centered in 0 and with Matérn covariance function as <span class="math inline">\(\tau^2\)</span>. <span class="math inline">\(w_{i}\)</span> addresses the spatial autocorrelation between observation through a Matérn covariance function <span class="math inline">\(\mathcal{C}(\cdot | \boldsymbol\psi_{1})\)</span> which in turn is tuned by hyper param included in <span class="math inline">\(\boldsymbol{\psi_1}\)</span>. Moreover the <span class="math inline">\(w_{i}\)</span> surface has to be passed in the formula method definition <a href="inla.html#example">4.3.2</a> via the <code>f()</code> function, so that INLA takes into cosideration the spatial component.</p>
<p><span class="math display">\[
\boldsymbol{y} \mid \boldsymbol{\theta}, \boldsymbol{\psi}_{1} \sim \mathrm{N}\left(\beta_{0}+ (\mathbf{X}_{i})^{\prime}\boldsymbol{\beta} + w_{i} ,  \tau^2 I_{n}\right)=\prod_{i=1}^{n} \mathrm{N}\left(y_{i} \mid \theta_{i}, \psi_{1}\right)
\]</span></p>
<p>Then at the <em>second level</em> the latent field <span class="math inline">\(\boldsymbol{\theta}\)</span> is characterized by a Normal distribution given the remaining hyper parameters <span class="math inline">\(\boldsymbol{\psi}_2\)</span>, recall the covariance matrix <span class="math inline">\(\boldsymbol{Q}^{-1}(\boldsymbol{\psi_{2}})\)</span>, depending on <span class="math inline">\(\boldsymbol{\psi_{2}}\)</span> hyperparameters, is handled now by a Matérn covariace function depeding on its hyperparamter. This is done in order to map the GP spatial surface into a GMRF by SPDE solutions.</p>
<p><span class="math display">\[
\boldsymbol{\theta} \mid \boldsymbol{\psi}_{2} \sim \mathrm{N}\left(\boldsymbol{0}, \mathcal{C}( \cdot , \cdot  \mid \boldsymbol{\psi}_{2})\right)
\]</span></p>
<p>In the end a <em>third level</em> hyper parameters <span class="math inline">\(\boldsymbol{\psi}=\left\{\boldsymbol{\psi_{1}}, \boldsymbol{\psi}_{2}\right\}\)</span> having some specified prior distribution i.e. <span class="math inline">\(\boldsymbol{\psi} \sim \pi(\boldsymbol{\psi})\)</span>,</p>
</div>
<div id="spatial-kriging" class="section level2">
<h2><span class="header-section-number">5.7</span> Spatial Kriging</h2>
<p>In Geostatistics the main interest resides in the spatial prediction of the spatial latent field pr the response variable at location not yet observed.
Assumed the model in the previous section, suppose that <span class="math inline">\(y^{\star}\)</span> is not a observed occurrence of the response variable at location <span class="math inline">\(s_{0}\)</span> (not in the data) of the GP <span class="math inline">\(w_{i}\)</span> spatial surface estimated through observed refereced points in <span class="math inline">\(\boldsymbol{y}\)</span>. As a consequence of exchangeability (first step previous section <a href="prdm.html#finalregr">5.6</a>) then <span class="math inline">\(\boldsymbol{y}^{\otimes}=\left\{\boldsymbol{y}, y^{\star}\right\}\)</span>. Then considering INLA notation it is obtained:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\pi\left(y^{\star} \mid \boldsymbol{y}\right)=\frac{\pi\left(\boldsymbol{y}, y^{\star}\right)}{\pi(\boldsymbol{y})} \text { from the conditional probability }\\
&amp;=\frac{\int \pi\left(y^{\star} \mid \theta\right) \pi(\boldsymbol{y} \mid \theta) \pi(\theta) \mathrm{d} \theta}{\pi(\boldsymbol{y})} \text { by exchangeability }\\
&amp;=\frac{\int \pi\left(y^{\star} \mid \theta\right) \pi(\theta \mid y) \pi(y) \mathrm{d} \theta}{\pi(y)} \text { applying Bayes&#39; theorem }\\
&amp;=\int \pi\left(y^{\star} \mid \boldsymbol{\theta}\right) \pi(\boldsymbol{\theta} \mid \boldsymbol{y}) \mathrm{d} \boldsymbol{\theta}
\end{aligned}
\]</span></p>
<p>A DAG representation might offr the intuition behind Prediction in spatial models:</p>
<div class="figure">
<img src="images/spatial_prediction.jpg" alt="" />
<p class="caption">Spatial prediction representation through DAG, source <span class="citation">Marta Blangiardo (<a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span></p>
</div>
<p>where <span class="math inline">\(\pi\left(y^{\star} \mid \boldsymbol{y}\right)\)</span> is said predictive distribution and it is meaningful only in the Bayesian framework since the posterior distribution is treated as a random variable, which is totally not true in frequentist statistics.</p>
</div>
<div id="model-checking" class="section level2">
<h2><span class="header-section-number">5.8</span> Model Checking</h2>
<p>(Incrociarlo con altri tesi)</p>
<p>Once the model is set up and fitted a resampling scheme has to be chosen in order to evaluate the model performance. One of the most used method to assess beyasian model quality is LOOCV cross validation and defualt choice fo R-INLA package. From data is left out one single observation and so that the Validation set is <span class="math inline">\(\boldsymbol{y}_{v} = \boldsymbol{y}_{-i}\)</span> and the Assessement set is a <span class="math inline">\(\boldsymbol{y}_{a} = \boldsymbol{y}_{i}\)</span>
the rest of the observations. Two KPI are assumed to be representative:</p>
<ul>
<li>CPO conditional predictive ordinate (pettit, 1990): <span class="math inline">\(CPO_{i} = \pi(y^{\star} \mid \boldsymbol{y}_{v})\)</span></li>
<li>PIT probability integral tranform (dawid, 1984): <span class="math inline">\(PIT_{i} = \pi(y^{\star} &lt; y_{i} \mid \boldsymbol{y}_{v})\)</span></li>
</ul>
<p>These quantities are used by default by setting control options in the <code>inla(control.compute = list())</code> list object by setting them equal o TRUE. Inla also provides an inner method to authomatically handlee failing in computing those two quantities, leadind to values of 1 when predictions are not reliable and the ipposite for 0.Moreover the empirical distribution of the PIT can be used to asses predictive performance: if it is Uniform, so there are not values that strongly differ from the others then the model is correctly checked. Otherwise if the dostribtuon almost approxiamtes any of the other possibles then the Cross validation assessement prediction has led incorrectly predict the “out of the bag” validation sample.</p>
<p>Posteerior checking method exploits a full cross validation where <span class="math inline">\(\boldsymbol{y}_{a} = \boldsymbol{y}_{v}\)</span> and it is called predictive checks. Th assessement set now is equal to the validation set,a s a consequence all the observation are evaluated twice. 4 quantities are driver to model estimate quality:</p>
<ul>
<li>the <em>posterior predictive distribution</em>: <span class="math inline">\(\pi(y^{\star} \mid \boldsymbol{y}) = \int \pi(y^{\star} \mid \theta_{i})\pi({\theta_{i}} \mid \boldsymbol{y})\mathrm{d}\theta_{i}\)</span> which is the likelihood of a replicate observation. When values are small that indicates that are those values are coming from tails, since the area under the curve (i.e. probability) is less. If this happens for many observation then outliers are driving the model leading to poor estimates</li>
<li>the <em>posterior predictive p-value</em> whose math expression is:<span class="math inline">\(\pi(y^{\star} \leq y_{i} \mid \boldsymbol{y})\)</span> for which values near to 0 and 1 indicates poor perfomances.</li>
<li><em>Root Mean Square Predictive Error RMSE</em>: <span class="math inline">\(\sqrt{\frac{1}{n} \sum_{i=1}^{n}(y_{i}-{y}^{\star}_{i})^{2}}\)</span></li>
<li><span class="math inline">\(R^2\)</span></li>
</ul>
<p>R-INLA has already antiticipated in chapter 4 section<a href="inla.html#example">4.3.2</a> have designed function to compute statistics on posterior distribution as <code>inla.pmarginal()</code> returning the cumulative density distribution.</p>
</div>
<div id="prior-specification" class="section level2">
<h2><span class="header-section-number">5.9</span> Prior Specification</h2>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Banerjee-Gelfand">
<p>Banerjee, Sudipto, Bradley P. Carlin, and Alan E. Gelfand. 2014. <em>Hierarchical Modeling and Analysis for Spatial Data</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/b17115">https://doi.org/10.1201/b17115</a>.</p>
</div>
<div id="ref-Bell2006">
<p>Bell, B Sue, Richard E Hoskins, Linda Pickle, and Daniel Wartenberg. 2006. <em>International Journal of Health Geographics</em> 5 (1): 49. <a href="https://doi.org/10.1186/1476-072x-5-49">https://doi.org/10.1186/1476-072x-5-49</a>.</p>
</div>
<div id="ref-blanchetscalliet">
<p>Blanchet-Scalliet, Christophette, Céline Helbert, Mélina Ribaud, and Céline Vial. 2019. “Four algorithms to construct a sparse kriging kernel for dimensionality reduction.” <em>Computational Statistics</em>, 1–21. <a href="https://hal.archives-ouvertes.fr/hal-01496521">https://hal.archives-ouvertes.fr/hal-01496521</a>.</p>
</div>
<div id="ref-Cameletti2012">
<p>Cameletti, Michela, Finn Lindgren, Daniel Simpson, and Håvard Rue. 2012. “Spatio-Temporal Modeling of Particulate Matter Concentration Through the SPDE Approach.” <em>AStA Advances in Statistical Analysis</em> 97 (2): 109–31. <a href="https://doi.org/10.1007/s10182-012-0196-3">https://doi.org/10.1007/s10182-012-0196-3</a>.</p>
</div>
<div id="ref-Capozza_Seguin_1996">
<p>Capozza, Dennis, and Paul Seguin. 1996. “Expectations, Efficiency, and Euphoria in the Housing Market.” <em>Regional Science and Urban Economics</em> 26 (February): 369–86. <a href="https://doi.org/10.1016/0166-0462(95)02120-5">https://doi.org/10.1016/0166-0462(95)02120-5</a>.</p>
</div>
<div id="ref-Clark_1995">
<p>Clark, Todd E. 1995. “Rents and prices of housing across areas of the United States. A cross-section examination of the present value model.” <em>Regional Science and Urban Economics</em> 25 (2): 237–47. <a href="https://ideas.repec.org/a/eee/regeco/v25y1995i2p237-247.html">https://ideas.repec.org/a/eee/regeco/v25y1995i2p237-247.html</a>.</p>
</div>
<div id="ref-Cressie_2015">
<p>Cressie, Noel. 2015. <em>Statistics for Spatial Data</em>. Revised Edition. Probability and Mathematical Statistics. Wiley-Interscience.</p>
</div>
<div id="ref-Bayesian_INLA_Rubio">
<p>Gómez Rubio, Virgilio. 2020. <em>Bayesian Inference with Inla</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9781315175584">https://doi.org/10.1201/9781315175584</a>.</p>
</div>
<div id="ref-Herath_Maier_2011">
<p>Herath, Shanaka, and Gunther Maier. 2011. “Hedonic House Prices in the Presence of Spatial and Temporal Dynamics.” <em>Territorio Italia - Land Administration Cadastre, Real Estate</em> 1 (January): 39–49.</p>
</div>
<div id="ref-Krainski2018">
<p>Krainski, Elias, Virgilio Gómez-Rubio, Haakon Bakka, Amanda Lenzi, Daniela Castro-Camilo, Daniel Simpson, Finn Lindgren, and Håvard Rue. 2018. <em>Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and INLA</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9780429031892">https://doi.org/10.1201/9780429031892</a>.</p>
</div>
<div id="ref-Krainski-Rubio">
<p>Krainski, Elias T. 2019. <em>Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and Inla</em>. Chapman; Hall/CRC.</p>
</div>
<div id="ref-Lancaster">
<p>Lancaster, Kelvin J. 1966. “A New Approach to Consumer Theory.” <em>Journal of Political Economy</em> 74 (2): 132–57. <a href="http://www.jstor.org/stable/1828835">http://www.jstor.org/stable/1828835</a>.</p>
</div>
<div id="ref-Li_Li_Ding_Hu_Chen_Wang_Peng_Shen_2020">
<p>Li, Huling, Hui Li, Zhongxing Ding, Zhibin Hu, Feng Chen, Kai Wang, Zhihang Peng, and Hongbing Shen. 2020. “Spatial Statistical Analysis of Coronavirus Disease 2019 (Covid-19) in China.” <em>Geospatial Health</em> 15 (1). <a href="https://doi.org/10.4081/gh.2020.867">https://doi.org/10.4081/gh.2020.867</a>.</p>
</div>
<div id="ref-Ling">
<p>Ling, Yuheng, and Y Ling. 2019. “Time, Space and Hedonic Prediction Accuracy Evidence from the Corsican Apartment Market.” <em>The Annals of Regional Science</em>, April, 28. <a href="https://doi.org/10.1007/s00168-019-00967-2">https://doi.org/10.1007/s00168-019-00967-2</a>.</p>
</div>
<div id="ref-Malpezzi">
<p>Malpezzi, Stephen. 2008. “Hedonic Pricing Models: A Selective and Applied Review.” In, 67–89. <a href="https://doi.org/10.1002/9780470690680.ch5">https://doi.org/10.1002/9780470690680.ch5</a>.</p>
</div>
<div id="ref-sellingVSrental">
<p>Manganelli, Benedetto, Pierluigi Morano, and Francesco Tajani. 2013. “Economic Relationships Between Selling and Rental Prices in the Italian Housing Market.” In.</p>
</div>
<div id="ref-Blangiardo-Cameletti">
<p>Marta Blangiardo, Michela Cameletti. 2015. <em>Spatial and Spatio-Temporal Bayesian Models with R-Inla</em>. Wiley.</p>
</div>
<div id="ref-Moraga2019">
<p>Moraga, Paula. 2019. <em>Geospatial Health Data</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9780429341823">https://doi.org/10.1201/9780429341823</a>.</p>
</div>
<div id="ref-PACI2017149">
<p>Paci, Lucia, María Asunción Beamonte, Alan E. Gelfand, Pilar Gargallo, and Manuel Salvador. 2017. “Analysis of Residential Property Sales Using Space–Time Point Patterns.” <em>Spatial Statistics</em> 21: 149–65. <a href="https://doi.org/https://doi.org/10.1016/j.spasta.2017.06.007">https://doi.org/https://doi.org/10.1016/j.spasta.2017.06.007</a>.</p>
</div>
<div id="ref-Rosen">
<p>Rosen, Sherwin. 1974. “Hedonic Prices and Implicit Markets: Product Differentiation in Pure Competition.” <em>Journal of Political Economy</em> 82 (1): 34–55. <a href="http://www.jstor.org/stable/1830899">http://www.jstor.org/stable/1830899</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inla.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="spde.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin"],
"google": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/NiccoloSalvini/thesis/edit/master/05-prd_modelling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Niccolo_Salvini_Thesis.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
