<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Point Referenced Data Modeling | RESTful Scraping API for Real Estate data, a Spatial Bayesian modeling perspective with INLA</title>
  <meta name="description" content="This is Niccolò Salvini master’s thesis project" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Point Referenced Data Modeling | RESTful Scraping API for Real Estate data, a Spatial Bayesian modeling perspective with INLA" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://niccolosalvini.github.io/Thesis/" />
  <meta property="og:image" content="https://niccolosalvini.github.io/Thesis/images/logo/spatial_logo.png" />
  <meta property="og:description" content="This is Niccolò Salvini master’s thesis project" />
  <meta name="github-repo" content="NiccoloSalvini/thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Point Referenced Data Modeling | RESTful Scraping API for Real Estate data, a Spatial Bayesian modeling perspective with INLA" />
  
  <meta name="twitter:description" content="This is Niccolò Salvini master’s thesis project" />
  <meta name="twitter:image" content="https://niccolosalvini.github.io/Thesis/images/logo/spatial_logo.png" />

<meta name="author" content="Niccolò Salvini" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="images/logo/spatial_logo.png" />
  <link rel="shortcut icon" href="images/logo/spatial_logo.ico" type="image/x-icon" />
<link rel="prev" href="inla.html"/>
<link rel="next" href="exploratory.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>
<link href="libs/leaflet-minimap-3.3.1/Control.MiniMap.min.css" rel="stylesheet" />
<script src="libs/leaflet-minimap-3.3.1/Control.MiniMap.min.js"></script>
<script src="libs/leaflet-minimap-3.3.1/Minimap-binding.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-171723874-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-171723874-1');
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="images/logo/spatial_logo.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminary Content</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#abstract"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="scraping.html"><a href="scraping.html"><i class="fa fa-check"></i><b>2</b> Web Scraping</a><ul>
<li class="chapter" data-level="2.1" data-path="scraping.html"><a href="scraping.html#reverse"><i class="fa fa-check"></i><b>2.1</b> A Gentle Introduction on Web Scraping</a></li>
<li class="chapter" data-level="2.2" data-path="scraping.html"><a href="scraping.html#anatomy-of-a-url-and-reverse-engineering"><i class="fa fa-check"></i><b>2.2</b> Anatomy of a url and reverse engineering</a><ul>
<li class="chapter" data-level="2.2.1" data-path="scraping.html"><a href="scraping.html#scraping-with-rvest"><i class="fa fa-check"></i><b>2.2.1</b> Scraping with <code id="ContentArchitecture">rvest</code></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="scraping.html"><a href="scraping.html#ProperScraping"><i class="fa fa-check"></i><b>2.3</b> Searching Technique for Scarping</a></li>
<li class="chapter" data-level="2.4" data-path="scraping.html"><a href="scraping.html#best-practices"><i class="fa fa-check"></i><b>2.4</b> Scraping Best Practices and Security provisions</a></li>
<li class="chapter" data-level="2.5" data-path="scraping.html"><a href="scraping.html#HTTPmethod"><i class="fa fa-check"></i><b>2.5</b> HTTP overview</a><ul>
<li class="chapter" data-level="2.5.1" data-path="scraping.html"><a href="scraping.html#spoofing"><i class="fa fa-check"></i><b>2.5.1</b> User Agent and further Identification Headers Spoofing</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="scraping.html"><a href="scraping.html#possibly"><i class="fa fa-check"></i><b>2.6</b> Dealing with failure</a></li>
<li class="chapter" data-level="2.7" data-path="scraping.html"><a href="scraping.html#parallelscraping"><i class="fa fa-check"></i><b>2.7</b> Parallel Scraping</a><ul>
<li class="chapter" data-level="2.7.1" data-path="scraping.html"><a href="scraping.html#parallel-furrrfuture"><i class="fa fa-check"></i><b>2.7.1</b> Parallel furrr+future</a></li>
<li class="chapter" data-level="2.7.2" data-path="scraping.html"><a href="scraping.html#parallel-foreachdofuture"><i class="fa fa-check"></i><b>2.7.2</b> Parallel foreach+doFuture</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="scraping.html"><a href="scraping.html#challenges"><i class="fa fa-check"></i><b>2.8</b> Open Challenges and Further Improvemements</a></li>
<li class="chapter" data-level="2.9" data-path="scraping.html"><a href="scraping.html#legal-profiles"><i class="fa fa-check"></i><b>2.9</b> Legal Profiles</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Infrastructure.html"><a href="Infrastructure.html"><i class="fa fa-check"></i><b>3</b> API Technology Stack</a><ul>
<li class="chapter" data-level="3.1" data-path="Infrastructure.html"><a href="Infrastructure.html#restful-api"><i class="fa fa-check"></i><b>3.1</b> RESTful API</a><ul>
<li class="chapter" data-level="3.1.1" data-path="Infrastructure.html"><a href="Infrastructure.html#plumberapi"><i class="fa fa-check"></i><b>3.1.1</b> Plumber HTTP API</a></li>
<li class="chapter" data-level="3.1.2" data-path="Infrastructure.html"><a href="Infrastructure.html#sanitize"><i class="fa fa-check"></i><b>3.1.2</b> Sanitization</a></li>
<li class="chapter" data-level="3.1.3" data-path="Infrastructure.html"><a href="Infrastructure.html#DoS"><i class="fa fa-check"></i><b>3.1.3</b> Denial Of Service (DoS)</a></li>
<li class="chapter" data-level="3.1.4" data-path="Infrastructure.html"><a href="Infrastructure.html#logging"><i class="fa fa-check"></i><b>3.1.4</b> Logging</a></li>
<li class="chapter" data-level="3.1.5" data-path="Infrastructure.html"><a href="Infrastructure.html#docs"><i class="fa fa-check"></i><b>3.1.5</b> RESTful API docs</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="Infrastructure.html"><a href="Infrastructure.html#docker"><i class="fa fa-check"></i><b>3.2</b> Docker</a><ul>
<li class="chapter" data-level="3.2.1" data-path="Infrastructure.html"><a href="Infrastructure.html#dockerfile"><i class="fa fa-check"></i><b>3.2.1</b> REST-API container</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="Infrastructure.html"><a href="Infrastructure.html#nginx"><i class="fa fa-check"></i><b>3.3</b> NGINX reverse Proxy Server and Authorization</a></li>
<li class="chapter" data-level="3.4" data-path="Infrastructure.html"><a href="Infrastructure.html#docker-compose"><i class="fa fa-check"></i><b>3.4</b> Docker-Compose</a></li>
<li class="chapter" data-level="3.5" data-path="Infrastructure.html"><a href="Infrastructure.html#HTTPS"><i class="fa fa-check"></i><b>3.5</b> HTTPS(ecure) and SSL certificates</a></li>
<li class="chapter" data-level="3.6" data-path="Infrastructure.html"><a href="Infrastructure.html#aws"><i class="fa fa-check"></i><b>3.6</b> AWS EC2 instance</a></li>
<li class="chapter" data-level="3.7" data-path="Infrastructure.html"><a href="Infrastructure.html#sdwf"><i class="fa fa-check"></i><b>3.7</b> Software CI/CD Workflow</a></li>
<li class="chapter" data-level="3.8" data-path="Infrastructure.html"><a href="Infrastructure.html#further-sf-integrations"><i class="fa fa-check"></i><b>3.8</b> Further SF Integrations</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inla.html"><a href="inla.html"><i class="fa fa-check"></i><b>4</b> INLA</a><ul>
<li class="chapter" data-level="4.1" data-path="inla.html"><a href="inla.html#LGM"><i class="fa fa-check"></i><b>4.1</b> The class of Latent Gaussian Models (LGM)</a></li>
<li class="chapter" data-level="4.2" data-path="inla.html"><a href="inla.html#approx"><i class="fa fa-check"></i><b>4.2</b> INLA Laplace Approximations</a></li>
<li class="chapter" data-level="4.3" data-path="inla.html"><a href="inla.html#rinla"><i class="fa fa-check"></i><b>4.3</b> R-INLA package</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="prdm.html"><a href="prdm.html"><i class="fa fa-check"></i><b>5</b> Point Referenced Data Modeling</a><ul>
<li class="chapter" data-level="5.1" data-path="prdm.html"><a href="prdm.html#GP"><i class="fa fa-check"></i><b>5.1</b> Gaussian Process (GP)</a></li>
<li class="chapter" data-level="5.2" data-path="prdm.html"><a href="prdm.html#spdeapproach"><i class="fa fa-check"></i><b>5.2</b> The Stochastic Partial Differential Equation (SPDE) approach</a></li>
<li class="chapter" data-level="5.3" data-path="prdm.html"><a href="prdm.html#hedonic-rental-price-models"><i class="fa fa-check"></i><b>5.3</b> Hedonic (rental) Price Models</a></li>
<li class="chapter" data-level="5.4" data-path="prdm.html"><a href="prdm.html#univariateregr"><i class="fa fa-check"></i><b>5.4</b> Point Referenced Regression for univariate spatial data</a><ul>
<li class="chapter" data-level="5.4.1" data-path="prdm.html"><a href="prdm.html#parameter-estimation"><i class="fa fa-check"></i><b>5.4.1</b> Parameter estimation</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="prdm.html"><a href="prdm.html#kriging"><i class="fa fa-check"></i><b>5.5</b> Spatial Kriging (prediction)</a></li>
<li class="chapter" data-level="5.6" data-path="prdm.html"><a href="prdm.html#model-criticism"><i class="fa fa-check"></i><b>5.6</b> Model Criticism</a></li>
<li class="chapter" data-level="5.7" data-path="prdm.html"><a href="prdm.html#priorsspec"><i class="fa fa-check"></i><b>5.7</b> Prior Specification</a></li>
<li class="chapter" data-level="5.8" data-path="prdm.html"><a href="prdm.html#spatial-krigingkriging-6.8"><i class="fa fa-check"></i><b>5.8</b> Spatial Kriging{#kriging} 6.8</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="exploratory.html"><a href="exploratory.html"><i class="fa fa-check"></i><b>6</b> Exploratory Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="exploratory.html"><a href="exploratory.html#prep"><i class="fa fa-check"></i><b>6.1</b> Data preparation</a><ul>
<li class="chapter" data-level="6.1.1" data-path="exploratory.html"><a href="exploratory.html#maps-and-geo-visualisations"><i class="fa fa-check"></i><b>6.1.1</b> Maps and Geo-Visualisations</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="exploratory.html"><a href="exploratory.html#counts-and-first-orientations"><i class="fa fa-check"></i><b>6.2</b> Counts and First Orientations</a></li>
<li class="chapter" data-level="6.3" data-path="exploratory.html"><a href="exploratory.html#text-mining-in-estate-review"><i class="fa fa-check"></i><b>6.3</b> Text Mining in estate Review</a></li>
<li class="chapter" data-level="6.4" data-path="exploratory.html"><a href="exploratory.html#missassimp"><i class="fa fa-check"></i><b>6.4</b> Missing Assessement and Imputation</a><ul>
<li class="chapter" data-level="6.4.1" data-path="exploratory.html"><a href="exploratory.html#missing-assessement"><i class="fa fa-check"></i><b>6.4.1</b> Missing assessement</a></li>
<li class="chapter" data-level="6.4.2" data-path="exploratory.html"><a href="exploratory.html#covariates-imputation"><i class="fa fa-check"></i><b>6.4.2</b> Covariates Imputation</a></li>
<li class="chapter" data-level="6.4.3" data-path="exploratory.html"><a href="exploratory.html#shinyapp-for-mesh-assessment"><i class="fa fa-check"></i><b>6.4.3</b> Shinyapp for mesh assessment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modelspec.html"><a href="modelspec.html"><i class="fa fa-check"></i><b>7</b> Model Selection &amp; Fitting</a></li>
<li class="chapter" data-level="8" data-path="application.html"><a href="application.html"><i class="fa fa-check"></i><b>8</b> Conclusions</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="8.1" data-path="appendix.html"><a href="appendix.html#gpbasics"><i class="fa fa-check"></i><b>8.1</b> Gaussian Process</a></li>
<li class="chapter" data-level="8.2" data-path="appendix.html"><a href="appendix.html#triangular"><i class="fa fa-check"></i><b>8.2</b> SPDE and Triangularization (YT speech: <span class="citation">Moraga (<span>2020</span>)</span>)</a></li>
<li class="chapter" data-level="8.3" data-path="appendix.html"><a href="appendix.html#laplaceapprox"><i class="fa fa-check"></i><b>8.3</b> Laplace Approximation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/NiccoloSalvini/tesi-prova" target="blank"> See Github Repository</a></li>
<li><a href="https://niccolosalvini.netlify.app/">About The Author</a></li>
<li><a Proudly published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">RESTful Scraping API for Real Estate data, a Spatial Bayesian modeling perspective with INLA</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prdm" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Point Referenced Data Modeling</h1>
<p>Geostatistical data are a collection of samples of geo type data indexed by coordinate Reference Systems (CRS), projected (e.g. Eastings and Northings) or unprojected (e.g. Latitude and Longitude), that originates from a spatially continuous phenomenon <span class="citation">(Moraga <a href="#ref-Moraga2019" role="doc-biblioref">2019</a>)</span>. Data as such can monitor a vast range of phenomena, e.g. accidental fisheries bycatch for endangered species <span class="citation">(Cosandey-Godin et al. <a href="#ref-CosandeyGodin2015" role="doc-biblioref">2015</a>)</span>, COVID19 severity and case fatality rates in Spain <span class="citation">(Moraga et al. <a href="#ref-Moragacovid2020" role="doc-biblioref">2020</a>)</span>, PM10 pollution concentration in a North-Italian region Piemonte <span class="citation">(Cameletti et al. <a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span>. Moreover a large geostatistical application takes place on Real Estate where Boston house prices lattice data from MASS <span class="citation">Venables and Ripley (<a href="#ref-mass" role="doc-biblioref">2002</a>)</span> package <span class="citation">Bivand, Gómez Rubio, and Rue (<a href="#ref-rubiorealestate" role="doc-biblioref">2015</a>)</span> are developed according to several spatial models, where apartment transaction prices are in Corsica (France) are modeled in time and space <span class="citation">(Ling <a href="#ref-Ling" role="doc-biblioref">2019</a>)</span>. All the Examples taken before and might document a spatial nature of data according to which closer observations can display similar values, this phenomenon is named spatial autocorrelation. Spatial autocorrelation conceptually stems from geographer Waldo Tobler whose famous quote, known as first law of geography, inspires geostatisticians:</p>
<blockquote>
<p>“Everything is related to everything else,
but near things are more related than distant things”</p>
<footer>
— Waldo R. Tobler
</footer>
</blockquote>
<p>Spatial data can be partitioned into three spatial data type whose modeling tools are specific to their respective category.</p>
<ul>
<li>Areal Data</li>
<li><strong>Point Referenced Data</strong></li>
<li>Point Pattern Data</li>
</ul>
<div class="figure"><span id="fig:prdmap"></span>
<img src="images/map.png" alt="" />
<p class="caption">Figure 5.1: Point Referenced Data map plot (<code>Leaflet</code> <span class="citation">Cheng, Karambelkar, and Xie (<a href="#ref-leaflet" role="doc-biblioref">2019</a>)</span>) of a RESTful API call on Milan Rental Real Estate 20-11-2019, Author’s Source</p>
</div>
<p>RESTful scraping API in <a href="Infrastructure.html#Infrastructure">3</a> allows to grab point referenced data (and covariates in tab. <a href="exploratory.html#exploratory">6</a>) by simply specifing the city or the sub-entity wanted. Moreover it allows also to specify the number of observation, this may result helpful in some context when complex models can not ingest large amounts of data or when the analyst’s interest resides in only certain type of house characteristics.</p>
<p>RESTful scraping API designed in chapter <a href="Infrastructure.html#Infrastructure">3</a> extracts geostatistical components in the form of Latitude and Longitude nested in a hidden source code JSON object. Resulting observations can be represented through a map as in fig. <a href="prdm.html#fig:prdmap">5.1</a>. API allows gather dat</p>
<p>Large areas with no housing within the polygons have
been removed (e.g. parks, the University of Zaragoza campus, hospital areas, etc.). What is
retained is, essentially, a full census of apartment sale transactions in and around the city center</p>
<p>Modeling methodologies described in this analysis will exclusively take into account point referenced techniques within the INLA algorithm.
Geostatical data can be considered as a stochastic process indexed on a continuous plane <span class="citation">(Arbia <a href="#ref-arbia2012spatial" role="doc-biblioref">2012</a>)</span> i.e Gaussian Process.
This information is essential to interpolate points and build a Gaussian Process over the y-studied variable domain in order to predict the phenomenon at locations not yet observed. GPs ,at first, have to be introduced and constrained to the properties of Stationarity and Isotropy and then they are considered with a convenient covariance function, i.e. Matèrn. The reason why Matérn is selected as candidate for covariance function relies, besides its inner flexibility, on the fact that GP whose covariance function is Matérn are able to determine a GMRF <a href="inla.html#gmrf"><strong>??</strong></a> through the Stochastic Partial Differential Equations (SPDE) approach <span class="citation">(<span class="citeproc-not-found" data-reference-id="Lindren2011"><strong>???</strong></span>)</span>. The main benefit proceeding from a GP to a GMRF arises from the good computational properties that the latter appreciate enabling to wrap up modeling around INLA and consequently benefiting from it. Hedonic Price Models brings to the present analysis the theoretical foundation according to which covariates are added to the model.
Spatial kriging is essential to predict the process at new locations given the continuous spatial surface.
In the end models have to be checked and verified with resampling schemes which are once again specific to the data type and the scope of the analysis.</p>
<div id="GP" class="section level2">
<h2><span class="header-section-number">5.1</span> Gaussian Process (GP)</h2>
<!-- prova a riscrivere GP -->
<p>Point referenced data are defined as realizations of a stochastic process indexed by space.</p>
<p><span class="math display">\[
Y(s) \equiv\{y(s), s \in \mathscr{D}\}
\]</span>
where <span class="math inline">\(\mathscr{D}\)</span> is a (fixed) subset of <span class="math inline">\(\mathbb{R}^{d}\)</span> (in the present work <em>Latitude</em> and <em>Longitude</em>, i.e. <span class="math inline">\(d=2\)</span>). The actual data can be then represented by a collection of observations <span class="math inline">\(\boldsymbol{\mathbf{y}}=\left\{y\left(s_{1}\right), \ldots, y\left(s_{n}\right)\right\}\)</span> (recall notation from previous chapter <a href="inla.html#LGM">4.1</a>) where the set <span class="math inline">\(\left(s_{1}, \ldots, s_{n}\right)\)</span> points to the spatial location where data has been considered. For example, following <span class="citation">Cameletti et al. (<a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span>, assume to have collection of samples from air pollutant measurements obtained by observing a set of monitoring stations. Then The stochastic process <span class="math inline">\(Y(s)\)</span> is observed in a fixed set of spatial indexes corresponding to the station locations (upwords arrows left in figure <a href="prdm.html#fig:prdproc">5.2</a>). This information is essential to interpolate points and build a spatially continuous surface (right panel in figure <a href="prdm.html#fig:prdproc">5.2</a>) over the y-studied variable domain in order to predict the phenomenon at locations not yet observed. <span class="citation">(Paci <a href="#ref-LecturePaci" role="doc-biblioref">2020</a>)</span>.</p>
<div class="figure"><span id="fig:prdproc"></span>
<img src="images/prdprocess.png" alt="" />
<p class="caption">Figure 5.2: Stockton data, Left: Spatial Lat and Long points pojected into the <span class="math inline">\(3^{rd}\)</span> dim <span class="math inline">\(\log(Price)\)</span>, Right: spatial interpolation of points, source <span class="citation">Marta Blangiardo (<a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span></p>
</div>
<p>The first step in defining a spatial model within INLA is to impose a LGM which reuires at first to identify a probability distribution for the observed data <span class="math inline">\(\boldsymbol{\mathbf{y}}\)</span>. Usually are drawn distributions from the <em>Exponential family</em>, indexed by a set of parameters <span class="math inline">\(\boldsymbol\theta\)</span> as in <a href="inla.html#LGM">4.1</a>, accounting for the spatial correlation — note that for the sake of simplicity we slightly abuse the notation and index the generic spatial point or area by using just the subscript <span class="math inline">\(i\)</span>, rather than the indicator <span class="math inline">\(s_i\)</span>, in the following.
In the case of geostatistical data, the model parameters <span class="math inline">\(\boldsymbol\theta\)</span>, folllwing notation imposed in chapter <a href="inla.html#inla">4</a> are defined as a latent stationary Gaussian Process (GP). The GP theoretical foundations and the spatial intuition are offered as a companion in the appendix <a href="appendix.html#gpbasics">8.1</a>.</p>

<div class="definition">
<span id="def:GP" class="definition"><strong>Definition 5.1  (GP definition)  </strong></span>A collection of <span class="math inline">\(n\)</span> random variables, such as <span class="math inline">\(Y(s_{1}), Y(s_{2}) , \ldots, Y(s_{n})\)</span> that are <em>valid</em> and <em>finite</em> stochastic processes are said to be a <strong>GP</strong> if for any set of spatial index <span class="math inline">\(n\)</span> and for each set of corresponding locations <span class="math inline">\(\left\{y\left(s_{1}\right), \ldots, y\left(s_{n}\right)\right\}\)</span> follows a <em>multivariate Gaussian</em> distribution with mean <span class="math inline">\(\boldsymbol{\mu}=\left\{\mu\left(s_{1}\right), \ldots, \mu\left(s_{n}\right)\right\}\)</span> and covariance matrix <span class="math inline">\(\mathbf{Q}^{-1}_{i,j}, \forall i \neq j\)</span> defined then by a covariance function <span class="math inline">\(\mathscr{\cdot, \cdot}\)</span>
</div>

<p>The latent GP are in function of some hyper-parameters <span class="math inline">\(\boldsymbol\psi\)</span> and their respective prior <span class="math inline">\(\pi(\boldsymbol\psi)\)</span>. Moreover a GP is completely characterized by a mean <span class="math inline">\(\boldsymbol{\mu}=\left(\mu_{1}, \ldots, \mu_{n}\right)^{\prime}\)</span> and a spatially structured covariance matrix <span class="math inline">\(\boldsymbol{Q^{-1}}\)</span> as multivariate Normal distribution, whose generic element is <span class="math inline">\(\boldsymbol{Q^{-1}}_{i j}=\operatorname{Cov}(\theta_{i}, \theta_{j})=\sigma^2_{\mathscr{C}} \mathscr{C}(\Delta_{i j})\)</span>, where <span class="math inline">\(\sigma_{\mathscr{C}}^{2}\)</span> is the variance component and for <span class="math inline">\(i, j = 1, \ldots, n\)</span>. <span class="math inline">\(\mathscr{C}\left( \cdot, \cdot \right)\)</span> function generally ensures that all the values that are close together in input space will produce output values that are close together, by inheriting the <em>validity</em> and <em>positive definitness</em> characteristics from the GP. The spatial stochastic process has also to satisfy two important properties <strong>stationary</strong>, <strong>Isotropy</strong> (both of the two relaxable at certain computational and modeling cost.
A process is said <strong>stationary</strong> i.e. weak stationary, if process values at any two locations can be summarized by a covariance function <span class="math inline">\(\mathscr{C(\Delta_{i j})}\)</span> depending only on the distance. In other words it is invariant under <em>translation</em> <span class="citation">(Krainski <a href="#ref-Krainski-Rubio" role="doc-biblioref">2019</a>)</span>.
A process is said <strong>Isotropic</strong> if the covariance function depends only on the between-points distance <span class="math inline">\(\Delta_{i j}=\left\|s_{i}-s_{j}\right\|\)</span> (in this context <em>Euclidean</em>), so it is invariant under <em>rotation</em> <span class="citation">(<a href="#ref-Krainski-Rubio" role="doc-biblioref">2019</a>)</span>. A further way of seeing this property is that Isotropy implies concentric decaying contours <span class="citation">(Paci <a href="#ref-LecturePaci" role="doc-biblioref">2020</a>)</span>, green in <a href="prdm.html#fig:isoovsanis">5.3</a>, that implies the vanishing of spatial dependence <span class="citation">(Marta Blangiardo <a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span>, and so for covariance values.</p>
<div class="figure"><span id="fig:isoovsanis"></span>
<img src="images/isotropyVSanisotropy.png" alt="" />
<p class="caption">Figure 5.3: Left: isotropy concentric decaying contours, Right: anisotropy concentric decaying contours, source <span class="citation">Blanchet-Scalliet et al. (<a href="#ref-blanchetscalliet" role="doc-biblioref">2019</a>)</span></p>
</div>
<p>In spatial statistics the assumption of isotropy is very frequent despite being restrictive for describing the rich variety of interactions that can characterize spatial processes. Anyway assuming the property it offers a wide range of underlying functions that can model spatial dependence for which three are the most common ones <span class="citation">(Krainski et al. <a href="#ref-Krainski2018" role="doc-biblioref">2018</a>)</span>, where all the parameters below are special quantities derived from the emphirical covariance function. <em>(qui puoi aggingere le grandezze delle robe sotto)</em></p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text { Exponential } \quad \mathscr{C}(\mathbf{ \Delta_{i j}})=\left\{\begin{array}{cl}
\tau^{2}_{\mathscr{C}}+\sigma^{2}_{\mathscr{C}} &amp; \text { if }  \Delta_{i j}=0 \\
\sigma^{2}_{\mathscr{C}} \exp (-\phi_{\mathscr{C}} \Delta_{i j}) &amp; \text { if } \Delta_{i j}&gt;0 
\end{array}\right.\\
&amp;\text { Gaussian } \quad \mathscr{C}(\mathbf{ \Delta_{i j}})=\left\{\begin{array}{cl}
\tau^{2}_{\mathscr{C}}+\sigma^{2}_{\mathscr{C}} &amp; \text { if } \Delta_{i j}=0 \\
\sigma^{2}_{\mathscr{C}} \exp \left(-\phi^{2}_{\mathscr{C}}  \Delta_{i j}^{2}\right) &amp; \text { if } \Delta_{i j}&gt;0 
\end{array}\right. \\
&amp;\text { Matérn } \quad \mathscr{C}(\mathbf{ \Delta_{i j}})=\left\{\begin{array}{cl}
\tau^{2}_{\mathscr{C}}+\sigma^{2}_{\mathscr{C}} &amp; \text { if } \Delta_{i j}=0 \\
\frac{\sigma^{2}_{\mathscr{C}}}{2^{\nu-1} \Gamma(\nu)}(\phi_{\mathscr{C}}  \Delta_{i j})^{\nu} K_{\nu}(\phi_{\mathscr{C}}  \Delta_{i j}) &amp; \text { if } \Delta_{i j}&gt;0
\end{array}\right.
\end{aligned}
\]</span></p>
<p>In particular the focus is on the <em>Matérn</em> – as it is required by the SPDE approach in Section <a href="prdm.html#spdeapproach">5.2</a> – and this should not be intended as a restriction. In fact, as described in Guttorp and Gneiting (2006) <em>miss lit</em>, the Matèrn family is a very flexible class. Matérn is tuned mainly by two hyper-parameters, a scaling one <span class="math inline">\(\kappa&gt;0\)</span>, usually set equal to the range <span class="math inline">\(\sigma_{\mathscr{C}}^{2}\)</span> i.e. the distance at which the spatial dependence becomes negligible, by the relation <span class="math inline">\(\sigma_{\mathscr{C}}^{2}=\frac{\sqrt{8 \lambda}}{\kappa}\)</span>), and a smoothing one <span class="math inline">\(\nu&gt;0\)</span>. A <em>isotropic</em> Matérn covariance expression is obtained by isolating the <span class="math inline">\(\sigma_{\mathscr{C}}^{2}\)</span>, the variance component <span class="citation">(Cressie <a href="#ref-Cressie_2015" role="doc-biblioref">2015</a>)</span>:</p>
<p><span class="math display">\[
\mathscr{C}\left(\Delta_{i j}\right)=\frac{1}{\Gamma(\lambda) 2^{\lambda-1}}\left(\kappa \Delta_{i j}\right)^{\lambda} K_{\lambda}\left(\kappa \Delta_{i j}\right)
\]</span>
<span class="math inline">\(\Gamma(\nu)\)</span> is a Gamma function depending on <span class="math inline">\(\nu\)</span> values, <span class="math inline">\(K_{\nu}(\cdot)\)</span> is a modified Bessel function of second kind. The smoothness parameter <span class="math inline">\(\nu\)</span> in figure <a href="#fig:matern">5.4</a> takes 4 different values showing the flexibility of Matérn to relate different distances according to varying parameters. When <span class="math inline">\(\nu = 1\)</span> … When <span class="math inline">\(\nu = 1/2\)</span> it becomes the exponential covariance function, When <span class="math inline">\(\nu = 3/2\)</span> it uncovers a convenient closed form <span class="citation">(Paci <a href="#ref-LecturePaci" role="doc-biblioref">2020</a>)</span>, when <span class="math inline">\(\nu \approx \infty\)</span>, e.g. for graphical constraints <span class="math inline">\(\nu = 80\)</span>, it becomes Gaussian covariance function. In the the case shown in section <a href="prdm.html#spdeapproach">5.2</a> <span class="math inline">\(\sigma_{\mathscr{C}}^{2}\)</span> range is set equal to the distance at which dependence vanishes below .1, for any <span class="math inline">\(\lambda\)</span>.</p>
<p><strong>qui metti codici</strong>
<img src="images/matern.png" alt="Matérn function with 4 different values of \nu (upper right legend), kept \phi fixed, author’s source" /></p>
<!-- For simplicity lets consider $y$ point of interest observations $y\left(\boldsymbol{s}_{1}\right),y\left(\boldsymbol{s}_{2}\right), \ldots, y\left(\boldsymbol{s}_{n}\right)$ -->
<!-- from a random spatial process $Y(s_n)$, such that: $Y\left(\boldsymbol{s}_{1}\right),Y\left(\boldsymbol{s}_{2}\right), \ldots, Y\left(\boldsymbol{s}_{n}\right)$ observed at location $\boldsymbol{s}_{1}, \ldots, \boldsymbol{s}_{n}$. In the context of point reference data modeling each observation has to be considered as a partial realization of an unobserved/underlying random spatial process $\left\{Y(s): s \in D \subset \mathbb{R}^{2}\right\}$, where surface $D$ is a subset of r-dimensional Euclidean space $\mathbb{R}^{r}$.  -->
<!-- Moreover when $r = 1$ it is the most simple stochastic process widely explored in literature i.e. time series process. However geostatistical data always displays $r = 2$ (i.e. Latitutde and Longitude, Eastings and Northings) or eventually $r = 3$, when elevation data is available. The stochastic process $Y$ is observed in a fixed set of "monitoring stations" (arrows left in figure \@ref(fig:prdproc)) and inference can be done regarding moments of the realized interpolated process. This information is essential to build a spatially continuous surface (3D surface right part in figure \@ref(fig:prdproc)) over the y-studied variable in order to predict the phenomenon at locations not yet observed [@LecturePaci].   -->
<!-- ![3D scatterplot of point referenced data and a spatial surface for Stockton data, source @Blangiardo-Cameletti](images/prdprocess.png) -->
<!-- ```{definition,GP1,name="GP definition"} -->
<!-- A collection of $n$ random variables, such as $Y(s_{1}), Y(s_{2}) , \ldots, Y(s_{n})$ that are _valid_ spatial processes are said to be a **GP** if for any set of spatial index $n$ and for each set of corresponding locations $\left\{y\left(s_{1}\right), \ldots, y\left(s_{n}\right)\right\}$  follows a _multivariate Gaussian_ distribution with mean $\boldsymbol{\mu}=\left\{\mu\left(s_{1}\right), \ldots, \mu\left(s_{n}\right)\right\}$ and covariance matrix $\mathbf{Q}^{-1}_{i,j}, \forall i \neq j$ -->
<!-- ``` -->
<!-- The covariance matrix relates each observation to each of the others via a covariance function defined as $\mathcal{C}(\cdot)$. -->
<!-- GP in a spatial domain setting has to check two important properties in order to exploit INLA techniques, even though in some cases the assumptions can be both of the two relaxed: -->
<!-- - **Stationary**. -->
<!-- - **Isotropy**. -->
<!-- **Stationarity** in a stochastic process can be _strong_, _weak_ or _intrinsic_. The strong property forces the distribution of the process $\left\{y\left(s_{1}\right), \ldots, y\left(s_{n}\right)\right\}$ for any given spatial index $n$ and its correspondent location sets $s_{1,\ldots,n}$ to be the same as the one in $\left\{y\left(s_{1}+\boldsymbol{h}\right), \ldots, y\left(s_{n}+\boldsymbol{h}\right)\right\}$, where $h$ is a number belonging to $R^{2}$.  -->
<!-- On the other hand the weak property ensures that if the GP mean moment is constant over the study domain $\mu(\mathbf{s}) \equiv \mu$ (e.g. $E[Y(s)]=\mu, \forall s \in D$) then the covariance functions does depend only on the distance (euclidean $\left\|s_{i}-s_{j}\right\|$ distance) between each couple points. -->
<!-- Weak stationarity consequences are the most interesting: It does not matter whether observations are placed either in a specific region, nor the direction towards they are oriented, the covariance functions $\mathcal{C}(h)$ can summarize the process through the separation vector $\mathbf{h}$ i.e. $\mathcal{C}(\mathbf{s}, \mathbf{s}+\mathbf{h})=\mathcal{C}(\mathbf{h}), \forall \mathbf{h} \in \mathbb{R}^{r}$ [@Banerjee-Gelfand]. In other words weak stationarity in GP implies being invariant under _translation_ [@Krainski-Rubio]. The relationship between strong and weak is not bijective since being strong implies also being weak, but the opposite is not always true for non-Gaussian process. -->
<!-- Furthermore through the intrinsic stationary property it is meant that $E[Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s})]=0$, the second moment of the latter expression can be written as $E[Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s})]^{2}$ leading to $\operatorname{Var}(Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s}))$. Last expression is called _variogram_ whose mathematicla form is $2 \gamma(\mathbf{h})$, even tough its half,i.e. $\gamma(\mathbf{h})$, is more interpretable, namely _semivariogram_ [@Cressie_2015]. -->
<!-- Semivariograms are characterized by 3 tuning parameters circled in red in figure \@ref(fig:variogram): -->
<!-- - _range_ $\sigma^{2}$: At some offset distance, the variogram values will stop changing and reach a sort of “plateau”. The distance at which the effect occurs is called the range $\frac{\Delta\gamma(\mathrm{h})}{h} \approx 0$. -->
<!-- - _sill_ $\tau^{2}$: The “plateau” value at which the variogram stops changing $\frac{\Delta\gamma(\mathrm{h})}{h} = 0$. -->
<!-- - _nugget_ $\tau^{2}+\sigma^{2}$: The discontinuity at the origin. Although this theoretically should be zero, sampling error and short scale variability can cause it to be non-zero $\gamma(\mathrm{0})$. -->
<!-- ![Variogram explanation of its main components, author source](images/variogram.PNG)  -->
<!-- <!-- <!-- non so se tenere -->
<!-- <!-- da qui -->
<!-- <!-- -->
<!-- <!-- Furthermore since it is assumed to be true by the intrinsic stationary property that $E[Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s})]=0$, the second moment of the latter expression can be written as $E[Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s})]^{2}$ leading to $\operatorname{Var}(Y(\mathbf{s}+\mathbf{h})-Y(\mathbf{s}))$. Last expression is called _variogram_ and can be expressed with $2 \gamma(\mathbf{h})$, even tough its half,i.e. $\gamma(\mathbf{h})$, is more interpretable, namely _semivariogram_ [@Cressie_2015]. -->
<!-- <!-- The intuition behind the variogram is that the difference in value between two near points $Y(\mathbf{s}+\mathbf{h})$ and $Y(\mathbf{h})$ is expected to be small with respect to the ones farther ( _ergodicity_ of the spatial process  @Banerjee-Gelfand ), in compliance with the first law of geography by Tobler:  -->
<p>&lt;!– <!-- > "Everything is related to everything else,  -->
&lt;!– <!-- > but near things are more related than distant things" -->
&lt;!– <!-- > -->
&lt;!– <!-- >  <footer>--- Waldo R. Tobler</footer> --></p>
<!-- <!-- Semivariograms are an efficient tool to asses spatial continuity and contiguity but they are theoretical. However semivariograms can be fitted into existing data giving birth to empirical semivariograms which are then plotted against their separation vector. The plot can be used to verify the null hypothesis of spatial independence and variability of the process. The below expression is the empirical semivariogram functional form: -->
<!-- <!-- $$\hat{\gamma}(t)=\frac{1}{2}|N(t)| \sum_{\left(\mathbf{s}_{i}, \mathbf{s}_{j}\right) \in N(t)}\left(Y\left(\mathbf{s}_{i}\right)-Y\left(\mathbf{s}_{j}\right)\right)^{2}$$ -->
<!-- <!-- where $N(t)$ is the set of location pairs such that $\left\|\mathbf{s}_{i}-\mathbf{s}_{j}\right\|=t$ and so $|N(t)|$ is the number of pairs in the set. As already guessed before empirical semivariogram values are expected to be small at short pairs distance and tends to increase when distance increases. The rational behind is that similar observations are expected to lay close together (small $h$) leading to lower semivariogram values ($\gamma(\mathbf{h})$), as opposite farther pairs obervations (big $h$) tend to be different and associated to greater semivariogram values. Flat semivariogram might indicate small spatial variance, since whether separation $h$ increases or not, semivariogram values remains the same $\frac{\Delta\gamma(\mathbf{h})}{\Delta\mathbf{h}}\approx0$. Semivariograms might be implied earlier in the modeling process to to evaluate the presence of any spatial pattern. Then they are also implied in the model checking stage with the aim to asses if any spatial pattern is still present in the residuals.  -->
<!-- <!-- ![variogram example](images/variogram.png) -->
<!-- <!-- <!-- a qui -->
<!-- The process is said to be **Isotropic** if the covariance function depends only on the between-points distance $\left\|\mathbf{h}\right\|$, so it is invariant under _rotation_ [-@Krainski-Rubio]. A further way of seeing the property is that Isotropy implies concentric decaying contours [@LecturePaci], green in \@ref(fig:isoovsanis), that resemble the vanishing of spatial dependence [@@Blangiardo-Cameletti], and so it does covariance values. In spatial statistics the assumption of isotropy is very common despite being very restrictive for describing the rich variety of interactions that can characterize spatial processes. -->
<!-- Then if the last assumption does not hold and direction towards point are distant from each other matters within the spatial domain $D$, then is said to be **Anisotropic**, purple in \@ref(fig:isoovsanis).  -->
<!-- Formalizing the results: -->
<!-- $$\mathcal{C}(\mathbf{h})=\mathcal{C}(\|\mathbf{h}\|)$$ -->
<!-- ![Left: isotropy concentric decaying contours, Right: anisotropy concentric decaying contours, source @blanchetscalliet](images/isotropyVSanisotropy.png) -->
<!-- ## Spatial Covariance Function -->
<!-- The covariance function $\math{C}(\cdot)$ ensures that all the values that are close together in input space will produce output values that are close together. $\mathcal{C}(\cdot)$ needs to inherits the _validity_ characteristics from the random spatial process, furthermore it has to be _positive definite_. The covariance function specification is a critical part of modeling and will affect kriging \@ref(kriging) estimates, parameters and related uncertainty [@cressie2015statistics]. -->
<!-- In addition covariance function must share characteristic properties of functions, such as: -->
<!-- (cerca di capire queste...) -->
<!--  - Multiply valid covariance functions (summing independent random variables) -->
<!--  - Mixing covariance functions (mixing distributions) -->
<!--  - Convolving covariance functions, this will be very important ... -->
<!-- <!-- Below a generalized version for two random $i$th $j$th observations: -->
<!-- <!-- \begin{equation} -->
<!-- <!-- \operatorname{Cov}\left(y\left(s_{i}\right), y\left(s_{j}\right)\right) -->
<!-- <!-- (\#eq:cov) -->
<!-- <!-- \end{equation} -->
<!-- Covariance functions under stationary and isotropic GPs displays two important properties: they are constant in mean within $D$ i.e. $\mathcal{C}(\mathbf{s}, \mathbf{s}+\mathbf{h})=\mathcal{C}(\mathbf{h}), \forall \mathbf{h} \in \mathbb{R}^{r}$ and they depends on distance vector $\mathbf{h}$, not direction i.e. $\mathcal{C}(\mathbf{h})=\mathcal{C}(\|\mathbf{h}\|)$ -->
<!-- There are many covariance functions and ways to relate distant points on a spatial domain $D$. Typically the choice of the Covariance can depend either on data or the scope of the analysis. Covariance functions are wrapped into hyper-parameters which are mainly three: -->
<!-- 1. _Range_: At some offset distance, the variogram values will stop changing and reach a “plateau”. The distance at which this occurs is called the range. -->
<!-- 2. _Sill_: The “plateau” value at which the variogram stops changing. -->
<!-- 3. _Nugget_: The discontinuity at the origin. Although this theoretically should be zero, sampling error and short scale variability can cause it to be non-zero -->
<!-- 4. partial sillò -->
<!-- ( espressione della covariance function insieme a alle $\sigma^2$ come: $\mathcal{C}(\mathbf{s}+\mathbf{h}, \mathbf{s} \mid \theta)=\sigma^{2} \mathbf{R}(\|h\| ; \phi)$ ) -->
<!-- spiega anche queste due sotto -->
<!-- $$ -->
<!-- \mathbf{w}=\left(w\left(\mathbf{s}_{1}\right), \ldots, w\left(\mathbf{s}_{n}\right)\right)^{\prime} \sim \mathrm{N}\left(\mathbf{0}, \sigma^{2} \mathbf{R}(\phi)\right) \text { where } \left.\mathbf{R}(\phi)_{i j}=\rho\left(\left\|\mathbf{s}_{i}-\mathbf{s}_{j}\right\| ; \phi\right)\right) -->
<!-- $$ -->
<!-- $\Sigma_{\theta}=\sigma^{2} \mathbf{R}(\phi)+\tau^{2} I_{n}$ -->
<!-- Three of the most applied covariance functions are presented below. -->
<!-- $$ -->
<!-- \begin{aligned} -->
<!-- &\text { Exponential } \quad \mathcal{C}(\mathbf{h})=\left\{\begin{array}{cl} -->
<!-- \tau^{2}+\sigma^{2} & \text { if }  h=0 \\ -->
<!-- \sigma^{2} \exp (-\phi h) & \text { if } h>0  -->
<!-- \end{array}\right.\\ -->
<!-- &\text { Gaussian } \quad \mathcal{C}(\mathbf{h})=\left\{\begin{array}{cl} -->
<!-- \tau^{2}+\sigma^{2} & \text { if } h=0 \\ -->
<!-- \sigma^{2} \exp \left(-\phi^{2} h^{2}\right) & \text { if } h>0  -->
<!-- \end{array}\right. \\ -->
<!-- &\text { Matérn } \quad \mathcal{C}(\mathbf{h})=\left\{\begin{array}{cl} -->
<!-- \tau^{2}+\sigma^{2} & \text { if } h=0 \\ -->
<!-- \frac{\sigma^{2}}{2^{\nu-1} \Gamma(\nu)}(\phi h)^{\nu} K_{\nu}(\phi h) & \text { if } h>0 -->
<!-- \end{array}\right. -->
<!-- \end{aligned} -->
<!-- $$ -->
<!-- ### Matérn Covariance Function{#Matern} -->
<!-- Matérn is crucial since when it is used together with a stationary and isotropic GP, the SPDE approach can provide a GMRF representation of the same process. Chapter \@ref(spde) discloses this fundamental property. Matérn can also be accounted as the most used in geostatistics [@Krainski2018] and [@Bayesian_INLA_Rubio]. Matérn is tuned mainly by two parameters, a scaling one $\kappa>0$, usually set equal to the range by the relation $\sigma^{2}=\frac{\sqrt{8 \lambda}}{\kappa}$) and a smoothing one $\nu>0$.  A _stationary_ and _isotropic_ Matérn covariance function has this form: -->
<!-- $$ -->
<!-- \mathcal{C}(\mathbf{h})=\left\{\begin{array}{ll} -->
<!-- \tau^{2}+\sigma^{2} & \text { if } h=0 \\ -->
<!-- \frac{\sigma^{2}}{2^{\nu-1} \Gamma(\nu)}(\phi t)^{\nu} K_{\nu}(\phi t) & \text { if } h>0 -->
<!-- \end{array}\right. -->
<!-- $$ -->
<!--  $\Gamma(\nu)$ is a Gamma function depending on $\nu$ values, $K_{\nu}(\cdot)$ is a modified Bessel function of second kind. The smoothness parameter $\nu$ in figure \@ref(fig:matern) below takes 4 different values showing the potentiality of Matérn to relates distances to covariance values. When $\nu = 1$ ... When $\nu = 1/2$ it becomes the exponential covariance function, When $\nu = 3/2$ it uncovers a convenient closed form [@LecturePaci], when $\nu \approx \infty$, in this case for representation purposes $\nu = 80$ it becomes Gaussian covariance function. -->
<!-- ![Matérn corr. function with 4 values of $\nu$, kept $\phi$ fixed, author's source](images/matern.png) -->
<!-- By decomposing it into a more granular form and cosidering two generic locations $\mathbf{S}_{i}$  and $\mathbf{S}_{j}$, -->
<!-- $$ -->
<!-- \operatorname{Cor}_{Matérn}\left(U\left(\mathbf{s}_{i}\right), U\left(\mathbf{s}_{j}\right)\right)=\frac{2^{1-\nu}}{\Gamma(\nu)}\left(\kappa\left\|\mathbf{s}_{i}-\mathbf{s}_{j}\right\|\right)^{\nu} K_{\nu}\left(\kappa\left\|\mathbf{s}_{i}-\mathbf{s}_{j}\right\|\right) -->
<!-- $$ -->
<!-- where $\|\cdot\|$ is the Euclidean distance, $\Gamma(\cdot)$ is a gamma function and $K_{\nu}(\cdot)$ is a modified Bessel function of second kind. The relationship that ties Matérn correlation and covariance is $\mathcal{C}(h_{i,j}) = \operatorname{Cov}_{Matérn}\left(U\left(\mathrm{s}_{i}\right), U\left(\mathrm{s}_{j}\right)\right) = \sigma_{u}^{2} \operatorname{Cor}_{M}\left(U\left(\mathbf{s}_{i}\right), U\left(\mathbf{s}_{j}\right)\right)$. -->
<!-- Then if $u(\mathbf{s})$ is a realization from $U(\mathbf{s})$ at $n$ locations the joint covariance matrix can be defined as each entry of the joint covariance matrix $\Sigma_{i, j}= \sigma_{u}^{2} \operatorname{Cor}_{M}\left(U\left(\mathbf{s}_{i}\right), U\left(\mathbf{s}_{j}\right)\right)$. Common customary choice is to assume that $U(.)$ in centered in 0. -->
</div>
<div id="spdeapproach" class="section level2">
<h2><span class="header-section-number">5.2</span> The Stochastic Partial Differential Equation (SPDE) approach</h2>
<p>Locations in the spatial setting are considered as realizations of a stationary, isotropic unobserved GP <span class="math inline">\(w(s)\)</span> to be estimated (<a href="prdm.html#GP">5.1</a>). Before approaching the problem with SPDE, GPs were treated as multivariate Gaussian densities and Cholesky factorizations were applied on the covariance matrices and then fitted with likelihood <span class="citation">(Paci <a href="#ref-LecturePaci" role="doc-biblioref">2020</a>)</span>. Covariance matrices in the context of spatial and spatio-temporal models <span class="citation">(Paci et al. <a href="#ref-PACI2017149" role="doc-biblioref">2017</a>; Cameletti et al. <a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span> are <span class="math inline">\(n \times n\)</span> whose dimension is produced the number of observations at each single location (at each time point in spatio-temporal) <span class="citation">(Blangiardo et al. <a href="#ref-BLANGIARDO201339" role="doc-biblioref">2013</a>)</span>. Covariance matrix as such are very dense and they were scaling with the order of <span class="math inline">\(\mathcal{O}\left(n^{3}\right)\)</span> <span class="citation">(Banerjee, Carlin, and Gelfand <a href="#ref-Banerjee-Gelfand" role="doc-biblioref">2014</a>)</span>. Problem were linked to the computational costs needed for linear algebra operations for model fitting and spatial interpolation as well as prediction <span class="citation">(Cameletti et al. <a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span>, having led to obvious <em>big-n</em> problem.
The breakthrough came with <span class="citation">Lindgren, Rue, and Lindström (<a href="#ref-Lindgren2011" role="doc-biblioref">2011</a>)</span> that proves that a stationary, isotropic (might be relaxed) GP with Matérn covariance can be represented as a GMRF using SPDE solutions by finite element method <span class="citation">(Krainski <a href="#ref-Krainski-Rubio" role="doc-biblioref">2019</a>)</span>. In other words given a GP whose covariance matrix is <span class="math inline">\(\boldsymbol{Q^{-1}}\)</span>, SPDE can provide a method to approximate <span class="math inline">\(\boldsymbol{Q^{-1}}\)</span> without the previous computational constraints. As a matter of fact SPDE are equations whose solutions are GPs with a chosen covariance function focused on satisfying the relationship SPDE specifies <span class="citation">(<a href="#ref-Krainski-Rubio" role="doc-biblioref">2019</a>)</span>.
Benefits are many but the most important is that the representation of the GP through a GMRF provides a sparse representation of the spatial effect through a sparse precision matrix <span class="math inline">\(\boldsymbol{Q}\)</span> . Sparse matrices enable convenient inner computation properties of GMRF <a href="inla.html#approx">4.2</a> which are exploited by INLA algorithm <a href="inla.html#inla">4</a> leading to a more feasible big-O <span class="math inline">\(\mathcal{O}\left(n^{3 / 2}\right)\)</span>. Mathematical details and deep understanding of the equations in SPDE are beyond the scope of the analysis. Luckily enough R-INLA has a set of functions that makes clear to the practitioner the minimal requirements to pass from discrete locations to their continuously indexed surface alter-ego.
In few words SPDE approach uses a finite element (FEM method) representation to shape the Matérn field as a linear combination of basis functions defined on a triangulation of the domain <span class="math inline">\(\mathcal{D}\)</span> <span class="citation">(<a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span>. What it intenally does is splitting the domain <span class="math inline">\(\mathcal{D}\)</span> into a number of non-intersecting triangles which converge in a common edge or corner. Then the initial vertices of the triangles are set at <span class="math inline">\(s_1 \ldots s_d\)</span>. In order to get a proper triangulation, useful for spatial prediction, additional vertices are then added. The more vertices are added the more the triangulation is accurate since many more triangles can better interpolate the surface reaching more complex shapes. Secondly SPDE projects the values of the trinagularization to the dicretized spatial surface with weighted sum of areas of the underlying triangles. A less superficial intuition is offered in the appendix in section <a href="appendix.html#triangular">8.2</a> on how SPDE computes triangularized valuez and how it projects the triangulation to the GRMF.<br />
To illustrate the concept of triangulation <span class="citation">Cameletti et al. (<a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span> provide a simple example for Piemonte PM10 concentration observed at 24 monitoring stations left in figure <a href="prdm.html#fig:piepm10">5.6</a> and using 123 vertices and a Piemonte borders, right in figure <a href="prdm.html#fig:piepm10">5.6</a>.</p>
<div class="figure"><span id="fig:piepm10"></span>
<img src="images/piemonte_pm10.jpg" alt="" />
<p class="caption">Figure 5.6: Left: monitoring stations in Piemonte region for PM10 pollution levels. Right: its triangulation using 123 vertices. <span class="citation">Cameletti et al. (<a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span> source</p>
</div>
<p>Any triangle height (the size of the spatial field at each vertix triangle) is calculated by weighted sum, with linear interpolation deciding the values within the triangle. Figure <a href="prdm.html#fig:spdesurf">5.7</a> shows a continously indexed random spatial field (left side of figure <a href="prdm.html#fig:spdesurf">5.7</a>) with the corresponding SPDE on the basis of a triangulation (right panel <a href="prdm.html#fig:spdesurf">5.7</a>).</p>
<div class="figure"><span id="fig:spdesurf"></span>
<img src="images/spde_indexedsurface.jpg" alt="" />
<p class="caption">Figure 5.7: Left: example of a spatial random field where <span class="math inline">\(X(s)= \cos(s_1)+\sin(s_2)\)</span>, Right: <span class="math inline">\(X(s)\)</span> SPDE representation given a triangulation, <span class="citation">Cameletti et al. (<a href="#ref-Cameletti2012" role="doc-biblioref">2012</a>)</span> source</p>
</div>
</div>
<div id="hedonic-rental-price-models" class="section level2">
<h2><span class="header-section-number">5.3</span> Hedonic (rental) Price Models</h2>
<p>The theoretical foundation of the Hedonic Price Models (from now on HPM) resides in the consumer utility theory of <span class="citation">Lancaster (<a href="#ref-Lancaster" role="doc-biblioref">1966</a>)</span> together with <span class="citation">Rosen (<a href="#ref-Rosen" role="doc-biblioref">1974</a>)</span> market equilibrium. According to Lancaster the utility of a commodity does not exist by itself, instead it exists as the sum of the utilities associated to its separable characteristics. Integrating Lancater, Rosen introduces HPM and suggests that each separate commodity characteristics are priced by the markets on the basis of supply and demand equilibra. Applying HPM to Real Estate in a market context, from the buy side house prices (indeed also rents) are set as the unit cost of each household attributes, conversely from the selling side the expenditures associated to build of each them.
Formalizing the results, Hedonic Price <span class="math inline">\(P\)</span> in Real Estate is expressed as a general <span class="math inline">\(f\)</span> functional form that takes as input the house characteristics vector <span class="math inline">\(\mathbf{C} = \{c_1,c_2, c_3, \ldots c_n\}\)</span>.</p>
<p><span class="math display">\[P=f\left(c_{1}, c_{2}, c_{3}, \ldots, c_{n}\right)\]</span></p>
<p>Vector <span class="math inline">\(\mathbf{C}\)</span> since now might contain a unidentified and presumably vast number of ungrouped characteristics. In this setting <span class="citation">Malpezzi (<a href="#ref-Malpezzi" role="doc-biblioref">2008</a>)</span> tried to organize house features by decomposing <span class="math inline">\(\mathbf{C}\)</span> into mutually exclusive and exhaustive subgroups. The vector components involves the house price <span class="math inline">\(P\)</span>, which is in a <span class="math inline">\(f\)</span> relation with: <span class="math inline">\(S\)</span>, the structural characteristics of the house, <span class="math inline">\(N\)</span>, the neighborhood characteristics, <span class="math inline">\(L\)</span>, the locational characteristics, <span class="math inline">\(C\)</span>, the contract conditions and <span class="math inline">\(T\)</span> time dimension (not included in the model). <span class="math inline">\(\beta\)</span> is the vector of the parameters to be estimated. Therefore:</p>
<p><span class="math display">\[P=f\left(S, N, L, C, T, \beta\right)\]</span>
However the critical part of studying house characteristics in geostatistics is the <em>estimation</em> and a recent (and not recent) number of emerging trends are observed <span class="citation">(Sheppard <a href="#ref-SHEPPARD19991595" role="doc-biblioref">1999</a>)</span>. Trends, other than the methods presented in this analysis suggests semi-parametric or non-parametric methods and applications of spatial econometrics <span class="citation">Ling (<a href="#ref-Ling" role="doc-biblioref">2019</a>)</span>. Researchers would also contend with problems ranging from variable selection to model specification <span class="citation">(<a href="#ref-Ling" role="doc-biblioref">2019</a>)</span>.
For semi-paramametric models a local polynomial regression is developed by <span class="citation">Clapp (<a href="#ref-clapp" role="doc-biblioref">2003</a>)</span>. The model provides a nonlinear term for the measurement of housing position values dependent on latitudes and longitudes.
Proper geoadditive models family was originally proposed by Kammann and Wand <span class="citation">(<a href="#ref-kammanwand" role="doc-biblioref">2003</a>)</span>, which offers a combination of additive modeling <span class="citation">(Buja, Hastie, and Tibshirani <a href="#ref-buja1989" role="doc-biblioref">1989</a>)</span> and a geostatistical component. As Ling <span class="citation">(<a href="#ref-Ling" role="doc-biblioref">2019</a>)</span> points out the candidates for the spatial component are many, e.g. kriging component <span class="citation">(Dey, Mukhopadhyay, and Adhikari <a href="#ref-dey2017metamodel" role="doc-biblioref">2017</a>)</span> (which will be then subsituted with a GP <a href="prdm.html#GP">5.1</a>) or a smooth spatial trend component based on a tensor product of longitude and latitude for which <span class="citation">Basile, Benfratello, and Castellani (<a href="#ref-basilebenfratmcast" role="doc-biblioref">2013</a>)</span> have investigated European industrial agglomeration externalities. The model outshines the other parameteric model performances by better managing spatial unobserved patterns. Furthermore they made available a third study dimension which is time <span class="citation">(<a href="#ref-Ling" role="doc-biblioref">2019</a>)</span>.
Spatial econometrics’ evolution trends are seen in <span class="citation">Shi and Lee (<a href="#ref-spateconomshifei" role="doc-biblioref">2017</a>)</span> and lately in <span class="citation">Anselin (<a href="#ref-spateconanslein" role="doc-biblioref">2010</a>)</span> where point referenced data are modeled with endogenous time varying spatial weights matrices and unobserved common factors and ultimately are fitted with traditional bayesian estimation methods as MCMC <span class="citation">(<a href="#ref-spateconanslein" role="doc-biblioref">2010</a>)</span>.
Then two further interesting modeling approach does not fall perfectly in the categories, but are higly considered in literature within the Hedonic Price models. <span class="citation">Dubé and Legros (<a href="#ref-dubelegros" role="doc-biblioref">2013</a>)</span> recognize that the modeling tools available analyzing point referenced data were not sufficient to take into account all the dimensions according to which they want to evaluate the phenomenon. They acknowledge that <em>Moran’s I</em> index and his statistics test relies mainly on an exogenous specification of a spatial weights matrix <span class="citation">(<a href="#ref-dubelegros" role="doc-biblioref">2013</a>)</span>. As a result they assemble a spatio‐temporal weights matrix to evaluate spatial dependence through Moran’s I index whose application is on real estate data (selling) for Québec City from 1986 to 1996. The second approach was addressed in <span class="citation">Baltagi, Bresson, and Etienne (<a href="#ref-baltagiparis" role="doc-biblioref">2015</a>)</span> whose object is price estimation based on flats sold in the city of Paris over the period 1990–2003. This is a rich and unbalanced pseudo‒panel data which are modeled with spatial lag. Results displayed a nested structure of the Paris housing data, which have been tested with likelihood ratio. A similar approach was followed by Nardelli and Arbia <span class="citation">(Arbia and Nardelli <a href="#ref-arbia2020spatial" role="doc-biblioref">2020</a>)</span> which collected crowdsourced as well as webscraped (as in section <a href="scraping.html#scraping">2</a>) data and lately applied Spatial Lag Model (SLM) on a “post-sampled” <span class="citation">(Arbia et al. <a href="#ref-arbia2020postsampling" role="doc-biblioref">2020</a>)</span> version of the same. As a result bias in the model is diminished, indeed variance of the estimators is increased.
<!-- Historically a first attempt to include spatial effect in urban economic literature is provided by _Alonso (1964) miss ref_. Its contribution was to raise voice on house prices (also rent) mainly depending on land price and a number of purely spatial covariates like CBD, the distance from City Business District. Other covariates were transport cost per kilometer and community income, even though they were defined also as spatial parameters through distances. The model proposed by Alonso is called monocentric since the centroid from which distances are calculated is only one. Moreover a first touch to spatial data theory was done since the CBD was defined as areal unit with well-defined boundaries of regular or irregular shape. However applications of the model were not convincing since empirical studies offered a different picture. Results displayed a Poly-centric areal structure (universities and Malls) which might be better explaining the variance of prices. The model also assumed that covariates like CBD are only informative within city center boundaries and then show no significance out of the core of the city. Poly-centric theory was also more coherent with the architectural and socio-economical evolution of cities during that times, therefore mono centric theory was then criticized and abandoned. Critics regarded also neighborhood quality measure and boundary problems _Dubin (1987) miss ref_. Dubin for these reasons developed a model including areal effects in the error term since handling these covariates was posing several hard challenges. Areal data choice for Dubin was forced since he was interested in land values, geostatics interest was not a focus also due to the difficulties in gathering accurate data. Coming to recent literature a change in focus has been made by switching from theory based model to estimation methods. As a consequence to the change in focus @Ling said that practitioners should spend more time in variable selection and model specification with respect to their specific need.  -->
<!-- As Ling has observed the emerging trends are in the field of semi-parametric and non-parametric methods -@Ling. Historically semi-parametric regression considers models indexed by spatial coordinates _Pace RK (1995)_. At the same time _Kammann and Wand (2003)_ gave birth to geoadditive models where the spatial component is added as a covariate. [...] -->
A further aspect of the problem is posed by scholars that do not consider rents to be representative for the actual value of real estate, as a result modeling choices should be calibrated on the market economic cricumstances. Nevertheless in many empirical analysis rent value are considered a proxy for real estate pricing when considered in long-run <span class="citation">(Herath and Maier <a href="#ref-Herath_Maier_2011" role="doc-biblioref">2011</a>)</span>. A further argument to endorse this hypothesis is brought by <span class="citation">Manganelli, Morano, and Tajani (<a href="#ref-sellingVSrental" role="doc-biblioref">2013</a>)</span> considering housing a commodity, then the selling or the rental option should be considered interchangeable economic actions with respect to same inner need to be satisfied. This assumption is also stronger in this context since Manganelli, Morano, and Tajani have centered their analysis on italian Real Estate data. Moreover <span class="citation">Capozza and Seguin (<a href="#ref-Capozza_Seguin_1996" role="doc-biblioref">1996</a>)</span> discussed on how much rent-price ratio predicts future changes both in rents and prices. Among all the other points raised they brought the decomposition of rent-price ratio into two parts: the predictable part and the unexplained residuals part. The predictable part was discovered to be negatively correlated with price changes, in other words cities in which prices are relatively high with respect to rents are associated with higher capital gains that might justify that misalignment. This is also true for the opposite, that is cities in which prices are lower with respect to the rents, and this effect can not be associated to any local condition, realize lower capital gains. A further argument is offered by Clark <span class="citation">(Clark <a href="#ref-Clark_1995" role="doc-biblioref">1995</a>)</span> which went after the Capozza and Seguin work. Rent-price ratio is negatively correlated with following future changes in rents. In other words prices are still higher when areas in which they are observed documents an increase in rent prices.</p>
</div>
<div id="univariateregr" class="section level2">
<h2><span class="header-section-number">5.4</span> Point Referenced Regression for univariate spatial data</h2>
<p>Since in HPM the relationships between the characteristics of the house, i.e. vector <span class="math inline">\(\mathbf{C}\)</span> and the price <span class="math inline">\(P\)</span> is not in any case fixed by econometric literature it is possible to assume any <span class="math inline">\(f\)</span> functional form. The open possibility to apply a wide range of relationship between covariates fit in the INLA setting, since Latent Gaussian Models are prepared to accept a any linear and non linear <span class="math inline">\(f\)</span> functions <a href="inla.html#LGM">4.1</a> through the <code>f()</code> method. Hedonic price models are, as a consequence, a subset of models that can be fitted into LGM and therefore by INLA method.</p>
<p>Moreover what the vast majority of econometric literature <em>(Greene, 2018)</em> suggest to apply a is log-linear / square root model. This is due to the fact that log transformation / square root smooths the skewness of prices normalizing the curve, leading to more accurate estimates. Having an exponential family generating process lowers even further computational cost for reasons linked to the <span class="math inline">\(\tilde\pi(\boldsymbol{\psi})\)</span> hyper param INLA approximation <span class="citation">(Marta Blangiardo <a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span>. Notation is taken from the previous chapter <a href="inla.html#inla">4</a>, for brevity purposes <span class="math inline">\(\boldsymbol{\beta}\)</span> <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\boldsymbol{y}\)</span> indicates vectors incorporating all their respective realizations and the <span class="math inline">\(s\)</span> spatial component is left out in favor of the observation pedix <span class="math inline">\(i\)</span>.<br />
The simplest log-linear bayesian regression model assumes linear relationship between predictors and a Normal data generating process: (log has been taken out for simplicity, bu it will be then considered in the regression setting) (valuta l’idea che per interpretabilità di modellarla come Gamma exponential family anzichè tenerla normale)</p>
<p><span class="math display">\[
\log{(y_{i})} \sim \operatorname{Normal}(\mu_{i}, \sigma^{2})
\]</span></p>
<p><span class="math display">\[
y_{i}=\mu_{i}+\varepsilon_{i}
\]</span></p>
<p>then by the following relationship <span class="math inline">\(E\left(y_{i} \mid \beta_{0}, \ldots, \beta_{M}, x_{i 1}, \ldots, x_{i M}\right)=\beta_{0}+\sum_{m=1}^{M} \beta_{m} x_{i m}\)</span> it is possible to specify a more general linear predictor (seen also in chapter <a href="inla.html#inla">4</a>) through an identity link function i.e. <span class="math inline">\(\eta_{i}=g\left(\mu_{i}\right)=\mu_{i}\)</span> obtaining:</p>
<p><span class="math display">\[
\eta_{i}=\beta_{0}+\sum_{m=1}^{M} \beta_{m} x_{m i}+\sum_{l=1}^{L} f_{l}\left(z_{l i}\right)
\]</span></p>
<p>Where, once again, the mean structure linearly depends on some <span class="math inline">\(\mathbf{X}\)</span> covariates, <span class="math inline">\(\boldsymbol{\beta}\)</span> coefficients, <span class="math inline">\(f_{l}(\cdot), \forall l \in 1 \ldots L\)</span> are a set of random effects defined in terms of a <span class="math inline">\(\boldsymbol{z}\)</span> set of covariates <span class="math inline">\(\boldsymbol{z}=\left(z_{1}, \ldots, z_{L}\right)\)</span> (e.g. rw, ar1) and <span class="math inline">\(\varepsilon_{i}\)</span> white noise error.
Priors have to be specified and a non informativeness for <span class="math inline">\(\tau^2 = 1/\sigma^2\)</span> and <span class="math inline">\(\boldsymbol{\beta}\)</span> is chosen, such that <span class="math inline">\(\pi(\tau^2) \propto 1\)</span> and <span class="math inline">\(\pi(\boldsymbol\beta) \propto 1\)</span>. As a consequence the conditional posterior for the parameters of interest <span class="math inline">\(\boldsymbol{\beta}\)</span> is:</p>
<p><span class="math display">\[
\boldsymbol{\beta} \mid \sigma^{2}, \boldsymbol{y}, \boldsymbol{X} \sim \operatorname{MVNormal}\left(\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{y}, \sigma^{2}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1}\right)
\]</span></p>
<p>where the mean structure corresponds to the OLS estimator: <span class="math inline">\(\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{y}\)</span> for <span class="math inline">\(\beta\)</span> and then to obtain the marginal posterior for <span class="math inline">\(\boldsymbol{\beta}\)</span> it is needed to integrate with respect to <span class="math inline">\(\sigma^2\)</span>.</p>
<p>In order to engage the spatial coordinate components into the regression setting <span class="math inline">\(w_{i}\)</span> has to be added to the equation. <span class="math inline">\(w_{i}\)</span> is set as a stationary and isotropic GP with mean 0 and variance as covariance function expressed as Matérn.
Recall that GP
The new regression setting integrates the <em>spatial error</em> part in the name of <span class="math inline">\(w_{i}\)</span> and a <em>non-spatial error</em> part <span class="math inline">\(\varepsilon_{i}\)</span> distributed normally with mean 0 and variance <span class="math inline">\(\tau^2\)</span> ,i.e. <span class="math inline">\(\mathrm{N}\left(0, \tau^{2}\right)\)</span>, which offers its contribution error to the nuggets via the covariance function.
Consequently there is one more parameter to estimate. It is worth mentioning that the distribution of <span class="math inline">\(w_{i}\)</span> at a finite number of points is considered a realization of a multivariate Gaussian distribution. In this case, the likelihood estimation is possible and it is the multivariate Gaussian distribution with covariance <span class="math inline">\(\Sigma\)</span>.</p>
<p><span class="math display">\[
\log(y_{i})= \beta_{0} + (\mathbf{X})^{\prime}\boldsymbol{\beta}+w_{i}+\varepsilon_{i}
\]</span></p>
<p>The covariance of the marginal distribution of <span class="math inline">\(y_{i}\)</span> at a finite number of locations is <span class="math inline">\(\Sigma_{y} = \Sigma + \tau^2\mathbf{I}\)</span>, where <span class="math inline">\(\mathbf{I}\)</span> denotes the indicator function (i.e., <span class="math inline">\(\mathbf{I}(i = i^{\prime})= 1\)</span> if <span class="math inline">\(i = i^{\prime}\)</span>, and 0 otherwise). This is a short extension of the basic GF model, and gives one additional parameter to estimate</p>
<p><span class="math display" id="eq:genreg">\[\begin{equation}
    \log(y_{i})=\mu_{i}+\varepsilon_{i}
\tag{5.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(y_{i}\)</span> is normally distributed as <span class="math inline">\(y_{i} \sim \operatorname{Normal}\left(\mu_{i}, \sigma^{2}\right)\)</span> and <span class="math inline">\(\mu_{i}\)</span> is the mean structure that linearly depends on some <span class="math inline">\(\mathbf{X}\)</span> covariates, <span class="math inline">\(\boldsymbol{\beta}\)</span> coefficients, <span class="math inline">\(f_{l}(\cdot), \forall l \in 1 \ldots L\)</span> are a set of random effects defined in terms of a <span class="math inline">\(\boldsymbol{z}\)</span> set of covariates <span class="math inline">\(\boldsymbol{z}=\left(z_{1}, \ldots, z_{L}\right)\)</span> (e.g. rw, ar1) and <span class="math inline">\(\varepsilon_{i}\)</span> white noise error. Please recall that the <span class="math inline">\(i\)</span>th pedices are the observations and the <span class="math inline">\(m\)</span>th pedices are the covariates. The structure is a repetition of what already seen in chapter <a href="inla.html#LGM">4.1</a></p>
<p><span class="math display" id="eq:linearpred">\[\begin{equation}
  \eta_{i}=\beta_{0}+\sum_{m=1}^{M} \beta_{m} x_{m i}+\sum_{l=1}^{L} f_{l}\left(z_{l i}\right)
\tag{5.2}
\end{equation}\]</span></p>
<p>The link function specified in this case is still identity, so that <span class="math inline">\(\eta_{i}=g\left(\mu_{i}\right)=\mu_{i}\)</span>. Nevertheless GLMs can be applied with different link function. when response variable has to stay between <span class="math inline">\([0,1]\)</span> (e.g. probabilities), the link function might be Logit, which leads to logistic regression. More generally expressed in vector notation:</p>
<p><span class="math display" id="eq:genregvec">\[\begin{equation}
  \log(y_{i})\left(\mathbf{s}_{i}\right)=\mathbf{x}\left(\mathbf{s}_{i}\right)^{\prime} \beta_{j}+\varepsilon\left(\mathbf{s}_{i}\right)
  \tag{5.3}
\end{equation}\]</span></p>
<p>where its OLS estimator is:
<span class="math display" id="eq:ols">\[\begin{equation}
  \hat{\beta}=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{y}
\tag{5.4}
\end{equation}\]</span></p>
<p>Moreover In the context of bayesian analysis a prior distribution has to be imposed on the regression coefficients <span class="math inline">\(\beta = \left\{\beta_{0}, \ldots, \beta_{J}\right\}\)</span> as well ad on the variance <span class="math inline">\(\sigma^{2}\)</span> of <span class="math inline">\(y_{i}\)</span>. When no expert information is provided vague priors are introduced, meaning that the regression should not be weighted too much on the priors choice.
Vague priors might be:</p>
<ul>
<li><span class="math inline">\(\beta_{m} \sim \operatorname{Normal}\left(0,10^{6}\right)\)</span> for the beta coefficients</li>
<li><span class="math inline">\(\log (\tau)=\log \left(1 / \sigma^{2}\right) \sim \log \operatorname{Gamma}\left(1,10^{-5}\right)\)</span> for precision</li>
</ul>
<p>Spatial modeling goal is to include spatial information from location into the model. This is done within the bayesian frameoùwork and INLA by adding <span class="math inline">\(w(\mathbf{s})\)</span> in the previous equation <a href="prdm.html#eq:genregvec">(5.3)</a>.</p>
<p><span class="math display">\[y\left(\mathbf{s}_{i}\right)=\mathbf{x}\left(\mathbf{s}_{i}\right)^{\prime}\beta_{j}+w(\mathbf{s})+\varepsilon\left(\mathbf{s}_{i}\right)\]</span></p>
<p>The <span class="math inline">\(w(\mathbf{s})\)</span> in the context of the analysis is approached as a stationary and isotropic GP<a href="prdm.html#GP">5.1</a> whose distribution by definition is multivariate Gaussian with mean <span class="math inline">\(\boldsymbol{\mu}(\mathbf{s}) = 0\)</span> and function of the spatial index <span class="math inline">\(\mathbf{s}\)</span> and covariance function <span class="math inline">\(\mathcal{C}( \cdot \mid \theta)\)</span> .
<span class="math inline">\(\varepsilon(\mathbf{s})\)</span> is iid and mean centered in 0 with variance <span class="math inline">\(\tau^{2}\)</span> and is called non-spatial error since it contributes to the nugget. The error term is pure since it interferes with the covariance function so that the model can embody the spatial component.
One of the major advantages of having a a spatial process embedded into a GP is <em>likelihood</em> based inference.</p>
<div id="parameter-estimation" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Parameter estimation</h3>
<p>Gaussian spatial models can be considered as GLM with a particular specification of the precision matrix <span class="math inline">\(\Sigma_{\theta}=\sigma^{2} \mathbf{R}(\phi)+\tau^{2} I_{n}\)</span>,
then the likelihood can be computed by:
<span class="math display">\[\mathbf{y} \mid \boldsymbol{\theta}, \boldsymbol{\beta} \sim \mathrm{N}\left(\mathbf{X} \beta, Q_{\theta}\right)\]</span>
where, <span class="math inline">\(\boldsymbol{\theta}=\left(\sigma^{2}, \tau^{2}, \phi\right)\)</span>
Since likelihood estimation is possible then MLE can be computed for <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\boldsymbol{\theta}\)</span> are <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> and <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>.
Then the estimation in vector notation is:</p>
<p><span class="math display">\[\hat{\boldsymbol{\beta}}_{M L E}=\left(\mathbf{X}^{\prime} Q^{-1} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} Q^{-1} \mathbf{y}\]</span></p>
<!-- ## Hierarchical Bayesian models{#hiermod} -->
<!-- Spatial Models are characterized by many parameters which in turn are tuned by other hyper-parameters. Traditionally Bayesian hierarchical models are not widely adopted since they have high computational burdens, indeed they can handle very complex interactions via random components, especially when dealing with spatio temporal data @Ling.  Blangiardo e Cameletti -@Blangiardo-Cameletti tried to approach the problem from a different angle offering an intuitive solution on how hierarchy relates different levels parameters. This is done by reversing the problem and starting from data back to parameters, instead the other way round. So taking a few steps back the problem can be reformulated by starting from grouping observation into categories and then trying to impose a hierarchical structure on data based on the categories. As a result observations might fall into different categories, underlining their natural characteristics, such as: some of them might belong to category _levels_ like males or females, married or not-married. Moreover diving into the specific problem house prices can be faceted by which floor they belong or whether they are assigned to different energy classes and many others more. As an example Blangiardo and Cameletti example consider grouping data according to just a single 9 _levels_ category. Data for the reasons stated before can be organized such that each single observation (squares in figure below) belongs to its respective mutually exclusive and collectively exhaustive category (circles in figure).   -->
<!-- ![9 levels cat vs observaitions, source @Blangiardo-Cameletti](images/simple.PNG) -->
<!-- Furthermore data can be partitioned into two meta-categories, _fist level_ and _second level_,  highlighting the parameter and hyper paramter chain roles. _First level_ are identified by sampling observations which are drawn by the same probability distribution (squares) . _Second level_ (circles) are categories and might be associated to a set of parameters $\theta=\left\{\theta_{1}, \ldots, \theta_{J}\right\}$. -->
<!-- Since the structure is hierarchical, a DAG (Directed Acyclical Graph) -@Blangiardo-Cameletti representation might sort out ideas. If categories are represented by different $\theta_{j}$ nodes and edges (arrows in the figure) are the logical belonging condition to the category then a single parameter $\theta$ model has the right figure form:  -->
<!-- ![DAG representation of hierarchical structure, source @Blangiardo-Cameletti](images/thetas.PNG)  ![chis, Blangiardo-Cameletti's source](images/chis.PNG) -->
<!-- To fully take into account the hierarchical structure of the data the model should also consider further lelvels. Since $\left\{\theta_{1}, \ldots, \theta_{J}\right\}$ are assumed to come from the same distribution $\pi(\theta_{j})$, then they are also assumed to be sharing information [@Blangiardo-Cameletti], (left figure).  When a further parameter $\boldsymbol{\psi}=\left\{\psi_{1}, \ldots, \psi_{K}\right\}$ is introduced, for which a prior distribution is specified, then the conditional distribution of $\boldsymbol{\theta}$ given $\boldsymbol{\psi}$ is: -->
<!-- $$ -->
<!-- \pi\left(\theta_{1}, \ldots, \theta_{J} \mid \boldsymbol{\psi}\right)=\int \prod_{j=1}^{J} \pi\left(\theta_{j} \mid \psi\right) \pi(\psi) \mathrm{d} \psi -->
<!-- $$ -->
<!-- This is possible thanks to the conditional independence property already encountered in chapter \@ref(inla), which means that each single $\theta$ is conditional independent given $\psi$ -->
<!-- This structure can extended to allow more than two levels of hierarchy since the marginal prior distributions of $\theta$ can be decomposed into the product of their conditional priors distributions given some hyper parameter $\psi$ as well as their prior distribution $\pi(\psi)$. -->
<!-- $$ -->
<!-- \pi(\boldsymbol{\theta})=\int \pi\left(\boldsymbol{\theta} \mid \boldsymbol{\psi}_{1}\right) \pi\left(\boldsymbol{\psi}_{1} \mid \boldsymbol{\psi}_{2}\right) \ldots \pi\left(\boldsymbol{\psi}_{L-1} \mid \boldsymbol{\psi}_{L}\right) \pi\left(\boldsymbol{\psi}_{L}\right) \mathrm{d} \boldsymbol{\psi}_{1} \ldots \mathrm{d} \boldsymbol{\psi}_{L} -->
<!-- $$ -->
<!-- $\boldsymbol{\psi}_{l}$ identifies the hyper pram for the $l_{th}$ level of hierarchy. Each further parameter level $\psi$ is conditioned to its previous in hierarchy level $l-1$ so that the parameter hierarchy chain is respected and all the linear combinations of parameters are carefully evaluated. The *Exchangeability* property enables to have higher $H$ nested DAG (i.e. add further $L$ levels) and to extend the dimensions in which the problem is evaluated, considering also time together with space. From a theoretical point of view there are no constraints to how many $L$ levels can be included in the model, but as a drawback the more the model is nested the more it suffers in terms of interpretability and computational power. Empirical studies have suggest that three levels are the desired amount since they offer a good bias vs variance trade-off. -->
</div>
</div>
<div id="kriging" class="section level2">
<h2><span class="header-section-number">5.5</span> Spatial Kriging (prediction)</h2>
<!-- prePRENDI DA KRAINSKI -->
<p>In Geostatistics the main interest resides in the spatial prediction of the spatial latent field pr the response variable at location not yet observed.
Assumed the model in the previous section, suppose that <span class="math inline">\(y^{\star}\)</span> is not a observed occurrence of the response variable at location <span class="math inline">\(s_{0}\)</span> (not in the data) of the GP <span class="math inline">\(w_{i}\)</span> spatial surface estimated through observed refereced points in <span class="math inline">\(\boldsymbol{y}\)</span>. As a consequence of exchangeability (first step previous section <a href="#inlahier"><strong>??</strong></a>) then <span class="math inline">\(\boldsymbol{y}^{\otimes}=\left\{\boldsymbol{y}, y^{\star}\right\}\)</span>. Then considering INLA notation it is obtained:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\pi\left(y^{\star} \mid \boldsymbol{y}\right)=\frac{\pi\left(\boldsymbol{y}, y^{\star}\right)}{\pi(\boldsymbol{y})} \text { from the conditional probability }\\
&amp;=\frac{\int \pi\left(y^{\star} \mid \theta\right) \pi(\boldsymbol{y} \mid \theta) \pi(\theta) \mathrm{d} \theta}{\pi(\boldsymbol{y})} \text { by exchangeability }\\
&amp;=\frac{\int \pi\left(y^{\star} \mid \theta\right) \pi(\theta \mid y) \pi(y) \mathrm{d} \theta}{\pi(y)} \text { applying Bayes&#39; theorem }\\
&amp;=\int \pi\left(y^{\star} \mid \boldsymbol{\theta}\right) \pi(\boldsymbol{\theta} \mid \boldsymbol{y}) \mathrm{d} \boldsymbol{\theta}
\end{aligned}
\]</span></p>
<p>A DAG representation might offr the intuition behind Prediction in spatial models:</p>
<div class="figure">
<img src="images/spatial_prediction.jpg" alt="" />
<p class="caption">Spatial prediction representation through DAG, source <span class="citation">Marta Blangiardo (<a href="#ref-Blangiardo-Cameletti" role="doc-biblioref">2015</a>)</span></p>
</div>
<p>where <span class="math inline">\(\pi\left(y^{\star} \mid \boldsymbol{y}\right)\)</span> is said predictive distribution and it is meaningful only in the Bayesian framework since the posterior distribution is treated as a random variable, which is totally not true in frequentist statistics.</p>
</div>
<div id="model-criticism" class="section level2">
<h2><span class="header-section-number">5.6</span> Model Criticism</h2>
<p>Since INLA can fit a wide range of model then the flexibility should be reflected by a mouldable tool to check model suitability.
Once the model is set up and fitted a resampling scheme has to be chosen in order to evaluate the model performance. One of the most used method to assess beyasian model quality is LOOCV cross validation and defualt choice fo R-INLA package. From data is left out one single observation and so that the Validation set is <span class="math inline">\(\boldsymbol{y}_{v} = \boldsymbol{y}_{-i}\)</span> and the Assessement set is a <span class="math inline">\(\boldsymbol{y}_{a} = \boldsymbol{y}_{i}\)</span>
the rest of the observations. Two KPI are assumed to be representative:</p>
<ul>
<li>CPO conditional predictive ordinate (pettit, 1990): <span class="math inline">\(CPO_{i} = \pi(y^{\star} \mid \boldsymbol{y}_{v})\)</span></li>
<li>PIT probability integral tranform (dawid, 1984): <span class="math inline">\(PIT_{i} = \pi(y^{\star} &lt; y_{i} \mid \boldsymbol{y}_{v})\)</span></li>
</ul>
<p>These quantities are used by default by setting control options in the <code>inla(control.compute = list())</code> list object by setting them equal o TRUE. Inla also provides an inner method to authomatically handlee failing in computing those two quantities, leadind to values of 1 when predictions are not reliable and the ipposite for 0.Moreover the empirical distribution of the PIT can be used to asses predictive performance: if it is Uniform, so there are not values that strongly differ from the others then the model is correctly checked. Otherwise if the dostribtuon almost approxiamtes any of the other possibles then the Cross validation assessement prediction has led incorrectly predict the “out of the bag” validation sample.</p>
<p>Posteerior checking method exploits a full cross validation where <span class="math inline">\(\boldsymbol{y}_{a} = \boldsymbol{y}_{v}\)</span> and it is called predictive checks. Th assessement set now is equal to the validation set,a s a consequence all the observation are evaluated twice. 4 quantities are driver to model estimate quality:</p>
<ul>
<li>the <em>posterior predictive distribution</em>: <span class="math inline">\(\pi(y^{\star} \mid \boldsymbol{y}) = \int \pi(y^{\star} \mid \theta_{i})\pi({\theta_{i}} \mid \boldsymbol{y})\mathrm{d}\theta_{i}\)</span> which is the likelihood of a replicate observation. When values are small that indicates that are those values are coming from tails, since the area under the curve (i.e. probability) is less. If this happens for many observation then outliers are driving the model leading to poor estimates</li>
<li>the <em>posterior predictive p-value</em> whose math expression is:<span class="math inline">\(\pi(y^{\star} \leq y_{i} \mid \boldsymbol{y})\)</span> for which values near to 0 and 1 indicates poor perfomances.</li>
<li><em>Root Mean Square Predictive Error RMSE</em>: <span class="math inline">\(\sqrt{\frac{1}{n} \sum_{i=1}^{n}(y_{i}-{y}^{\star}_{i})^{2}}\)</span></li>
<li><span class="math inline">\(R^2\)</span></li>
</ul>
<p>R-INLA has already antiticipated in chapter 4 section<a href="#example"><strong>??</strong></a> have designed function to compute statistics on posterior distribution as <code>inla.pmarginal()</code> returning the cumulative density distribution.</p>
</div>
<div id="priorsspec" class="section level2">
<h2><span class="header-section-number">5.7</span> Prior Specification</h2>
<p>The priors choice is the most central part of a Bayesian analysis and at the same time the weakest since any selection might be criticized. Priors expression involves a considerably high amount of subjectivity and domain experience which may be imported from other comparable literature works or results. However according to purists Bayesian priors should be decided <em>a-priori</em>, without either looking at the data, nor the posterior results. This can be tedious since many models are sensitive to priors, as evidenced in the example in sec. <a href="inla.html#rinla">4.3</a>. Priors may negatively impact posteriors when are
wrong and they usually require a later revision. The choice in this context is also more difficult since it is also constrained to LGM requirements for which the latent field demands them to be jointly Gaussian. <span class="citation">Simpson et al. (<a href="#ref-simpson2017" role="doc-biblioref">2017</a>)</span> provide a solid backbone knowledge on priors specification in Hierarchical models by setting up 4 guidelines principles on top of which it is built a new class said Penalized Complexity (PC) priors. Before jumping into the principles it is needed an abstract concept that goes by the name of “base model”. For a general density <span class="math inline">\(\pi(\mathbf{y} \,| \,\xi)\)</span> which is controlled by a flexibility parameter <span class="math inline">\(\xi\)</span> the base model is the most uncomplicated one in the class. Following the notation this would be the model corresponding to <span class="math inline">\(\xi = 0\)</span>. The base model ideally grabs the parameter choice with the lowest possible complexity given the model an set it as a ground benchmark. The following example regards base model for a a Gaussian Random effect and it considers a multivarite gaussian distributed with mean <strong>0</strong> and precision matrix <span class="math inline">\(\tau \boldsymbol{Q}\)</span>, i.e. <span class="math inline">\(\mathbf{y} \mid \xi \sim \operatorname{MVN}(\, 0\, ,\,\tau \boldsymbol{Q})\)</span>, where <span class="math inline">\(\tau=\xi^{-1}\)</span>. The base model tries to put the mass <span class="citation">(<a href="#ref-simpson2017" role="doc-biblioref">2017</a>)</span> on <span class="math inline">\(\xi = 0\)</span> since the base model in this case is a model without the random effect. At this point it is possible to present the building blocks, first priciple is <em>Occam’s razor</em> according to which priors should be weighted down in fuction of the distance between the added complexity and the base model i.e. simpler solutions are preferred. The second principle regards how it is measured complexity whose solution is found in KLD (Kullback–Leibler divergence) calculating distance <span class="math inline">\(d\)</span>. KLD in this context along with principle 1 affirms that the prior shall have high mass in areas where replacing the base model with the flexible model will not cause any information loss. Principle 3 is constant rate penalization that actually relates the distance <span class="math inline">\(d\)</span> to a constant penalization. In the end principle 4 regards a scale parameter which actually ends up not being very sharp in prior setting. A prior satistfyng all the requirements is said Penalized in Complexity.
Priors of this class therefore should be derived with respect to the specific content they are needed. In this context PC priors are seen for Gaussian Random effect, i.e. the GP process hyper parameter.
Assume to have a gaussian random effect modeling some sort of spatial dependece as in <a href="prdm.html#GP">5.1</a>, i.e. <span class="math inline">\(\mathbf{x} \sim \mathcal{N}\left(\mathbf{0}, \tau^{-1} \boldsymbol{Q}^{-1}\right)\)</span>. The base model considers the absence of the random effect which implies <span class="math inline">\(\tau \rightarrow \infty\)</span>, […] the applying principles priors take the form of an exponential distribution i.e. “type-2 Gumbel distribution” on the standard deviation (in contrast to the exponential on the precision seen in the default).</p>
<div class="figure"><span id="fig:priorcomp"></span>
<img src="images/new_prior.jpg" alt="" />
<p class="caption">Figure 5.8: New prior (dashed) with parameters (<span class="math inline">\(U = 0.968\)</span>,<span class="math inline">\(\alpha = 0.01\)</span>), and the <span class="math inline">\(\Gamma(shape = 1,rate = b)\)</span> prior (solid).</p>
</div>
<ul>
<li>wang genral prior specifications OK</li>
<li>wang 106 choice of priors OK</li>
<li>wang 216 choice of priors for GP OK</li>
<li>blangiardo 6.9 pagina 214 OK</li>
<li>pagina 197 rimando a 214 OK</li>
<li>leggere <span class="citation">Simpson et al. (<a href="#ref-simpson2017" role="doc-biblioref">2017</a>)</span> OK</li>
</ul>
</div>
<div id="spatial-krigingkriging-6.8" class="section level2">
<h2><span class="header-section-number">5.8</span> Spatial Kriging{#kriging} 6.8</h2>
<p>The most important aspect in geostatistics regards the possibility to predict response where the phenomenon is not yet observed as well as predicting on latent parameters also named kriging <span class="citation">(Gelfand et al. <a href="#ref-gelfand2010handbook" role="doc-biblioref">2010</a>)</span>. The name Kriging dates back to a South African mining engineer who actually was the the inventor of the methodology.</p>
<p>At first it may be convenient to look at general bayesian prediction</p>
<ul>
<li>general bayesian prediction (wang + balngiardo)</li>
<li>spartial prediction by Gelfand</li>
<li>integrating with paci</li>
<li>code from blangiardo</li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-spateconanslein">
<p>Anselin, Luc. 2010. “Thirty Years of Spatial Econometrics.” <em>Papers in Regional Science</em> 89 (1): 3–25. <a href="https://doi.org/https://doi.org/10.1111/j.1435-5957.2010.00279.x">https://doi.org/https://doi.org/10.1111/j.1435-5957.2010.00279.x</a>.</p>
</div>
<div id="ref-arbia2012spatial">
<p>Arbia, Giuseppe. 2012. <em>Spatial Data Configuration in Statistical Analysis of Regional Economic and Related Problems</em>. Vol. 14. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-arbia2020spatial">
<p>Arbia, Giuseppe, and Vincenzo Nardelli. 2020. “On Spatial Lag Models Estimated Using Crowdsourcing, Web-Scraping or Other Unconventionally Collected Data.” <a href="http://arxiv.org/abs/2010.05287">http://arxiv.org/abs/2010.05287</a>.</p>
</div>
<div id="ref-arbia2020postsampling">
<p>Arbia, Giuseppe, Gloria Solano-Hermosilla, Fabio Micale, Vincenzo Nardelli, and Giampiero Genovese. 2020. “Post-Sampling Crowdsourced Data to Allow Reliable Statistical Inference: The Case of Food Price Indices in Nigeria.” <a href="http://arxiv.org/abs/2003.12542">http://arxiv.org/abs/2003.12542</a>.</p>
</div>
<div id="ref-baltagiparis">
<p>Baltagi, Badi H., Georges Bresson, and Jean-Michel Etienne. 2015. “Hedonic Housing Prices in Paris: An Unbalanced Spatial Lag Pseudo-Panel Model with Nested Random Effects.” <em>Journal of Applied Econometrics</em> 30 (3): 509–28. <a href="https://doi.org/https://doi.org/10.1002/jae.2377">https://doi.org/https://doi.org/10.1002/jae.2377</a>.</p>
</div>
<div id="ref-Banerjee-Gelfand">
<p>Banerjee, Sudipto, Bradley P. Carlin, and Alan E. Gelfand. 2014. <em>Hierarchical Modeling and Analysis for Spatial Data</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/b17115">https://doi.org/10.1201/b17115</a>.</p>
</div>
<div id="ref-basilebenfratmcast">
<p>Basile, Roberto, Luigi Benfratello, and Davide Castellani. 2013. “Geoadditive Models for Regional Count Data: An Application to Industrial Location.” <em>Geographical Analysis</em> 45 (1): 28–48. <a href="https://doi.org/https://doi.org/10.1111/gean.12001">https://doi.org/https://doi.org/10.1111/gean.12001</a>.</p>
</div>
<div id="ref-rubiorealestate">
<p>Bivand, Roger, Virgilio Gómez Rubio, and Håvard Rue. 2015. “Spatial Data Analysis with R-Inla with Some Extensions.” <em>Journal of Statistical Software</em> 63 (February): 1–31. <a href="https://doi.org/10.18637/jss.v063.i20">https://doi.org/10.18637/jss.v063.i20</a>.</p>
</div>
<div id="ref-blanchetscalliet">
<p>Blanchet-Scalliet, Christophette, Céline Helbert, Mélina Ribaud, and Céline Vial. 2019. “Four algorithms to construct a sparse kriging kernel for dimensionality reduction.” <em>Computational Statistics</em>, 1–21. <a href="https://hal.archives-ouvertes.fr/hal-01496521">https://hal.archives-ouvertes.fr/hal-01496521</a>.</p>
</div>
<div id="ref-BLANGIARDO201339">
<p>Blangiardo, Marta, Michela Cameletti, Gianluca Baio, and Håvard Rue. 2013. “Spatial and Spatio-Temporal Models with R-Inla.” <em>Spatial and Spatio-Temporal Epidemiology</em> 7: 39–55. <a href="https://doi.org/https://doi.org/10.1016/j.sste.2013.07.003">https://doi.org/https://doi.org/10.1016/j.sste.2013.07.003</a>.</p>
</div>
<div id="ref-buja1989">
<p>Buja, Andreas, Trevor Hastie, and Robert Tibshirani. 1989. “Linear Smoothers and Additive Models.” <em>Ann. Statist.</em> 17 (2): 453–510. <a href="https://doi.org/10.1214/aos/1176347115">https://doi.org/10.1214/aos/1176347115</a>.</p>
</div>
<div id="ref-Cameletti2012">
<p>Cameletti, Michela, Finn Lindgren, Daniel Simpson, and Håvard Rue. 2012. “Spatio-Temporal Modeling of Particulate Matter Concentration Through the SPDE Approach.” <em>AStA Advances in Statistical Analysis</em> 97 (2): 109–31. <a href="https://doi.org/10.1007/s10182-012-0196-3">https://doi.org/10.1007/s10182-012-0196-3</a>.</p>
</div>
<div id="ref-Capozza_Seguin_1996">
<p>Capozza, Dennis, and Paul Seguin. 1996. “Expectations, Efficiency, and Euphoria in the Housing Market.” <em>Regional Science and Urban Economics</em> 26 (February): 369–86. <a href="https://doi.org/10.1016/0166-0462(95)02120-5">https://doi.org/10.1016/0166-0462(95)02120-5</a>.</p>
</div>
<div id="ref-leaflet">
<p>Cheng, Joe, Bhaskar Karambelkar, and Yihui Xie. 2019. <em>Leaflet: Create Interactive Web Maps with the Javascript ’Leaflet’ Library</em>. <a href="https://CRAN.R-project.org/package=leaflet">https://CRAN.R-project.org/package=leaflet</a>.</p>
</div>
<div id="ref-clapp">
<p>Clapp, John M. 2003. “A Semiparametric Method for Valuing Residential Locations: Application to Automated Valuation.” <em>The Journal of Real Estate Finance and Economics</em> 27 (3): 303–20. <a href="https://doi.org/https://doi.org/10.1023/A:1025838007297">https://doi.org/https://doi.org/10.1023/A:1025838007297</a>.</p>
</div>
<div id="ref-Clark_1995">
<p>Clark, Todd E. 1995. “Rents and prices of housing across areas of the United States. A cross-section examination of the present value model.” <em>Regional Science and Urban Economics</em> 25 (2): 237–47. <a href="https://ideas.repec.org/a/eee/regeco/v25y1995i2p237-247.html">https://ideas.repec.org/a/eee/regeco/v25y1995i2p237-247.html</a>.</p>
</div>
<div id="ref-CosandeyGodin2015">
<p>Cosandey-Godin, Aurelie, Elias Teixeira Krainski, Boris Worm, and Joanna Mills Flemming. 2015. “Applying Bayesian Spatiotemporal Models to Fisheries Bycatch in the Canadian Arctic.” <em>Canadian Journal of Fisheries and Aquatic Sciences</em> 72 (2): 186–97. <a href="https://doi.org/10.1139/cjfas-2014-0159">https://doi.org/10.1139/cjfas-2014-0159</a>.</p>
</div>
<div id="ref-Cressie_2015">
<p>Cressie, Noel. 2015. <em>Statistics for Spatial Data</em>. Revised Edition. Probability and Mathematical Statistics. Wiley-Interscience.</p>
</div>
<div id="ref-dey2017metamodel">
<p>Dey, S, T Mukhopadhyay, and S Adhikari. 2017. “Metamodel Based High-Fidelity Stochastic Analysis of Composite Laminates: A Concise Review with Critical Comparative Assessment.” <em>Composite Structures</em> 171: 227–50.</p>
</div>
<div id="ref-dubelegros">
<p>Dubé, Jean, and Diègo Legros. 2013. “A Spatio-Temporal Measure of Spatial Dependence: An Example Using Real Estate Data*.” <em>Papers in Regional Science</em> 92 (1): 19–30. <a href="https://doi.org/https://doi.org/10.1111/j.1435-5957.2011.00402.x">https://doi.org/https://doi.org/10.1111/j.1435-5957.2011.00402.x</a>.</p>
</div>
<div id="ref-gelfand2010handbook">
<p>Gelfand, Alan E, Peter Diggle, Peter Guttorp, and Montserrat Fuentes. 2010. <em>Handbook of Spatial Statistics</em>. CRC press.</p>
</div>
<div id="ref-Herath_Maier_2011">
<p>Herath, Shanaka, and Gunther Maier. 2011. “Hedonic House Prices in the Presence of Spatial and Temporal Dynamics.” <em>Territorio Italia - Land Administration Cadastre, Real Estate</em> 1 (January): 39–49.</p>
</div>
<div id="ref-kammanwand">
<p>Kammann, E. E., and M. P. Wand. 2003. “Geoadditive Models.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 52 (1): 1–18. <a href="https://doi.org/https://doi.org/10.1111/1467-9876.00385">https://doi.org/https://doi.org/10.1111/1467-9876.00385</a>.</p>
</div>
<div id="ref-Krainski2018">
<p>Krainski, Elias, Virgilio Gómez-Rubio, Haakon Bakka, Amanda Lenzi, Daniela Castro-Camilo, Daniel Simpson, Finn Lindgren, and Håvard Rue. 2018. <em>Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and INLA</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9780429031892">https://doi.org/10.1201/9780429031892</a>.</p>
</div>
<div id="ref-Krainski-Rubio">
<p>Krainski, Elias T. 2019. <em>Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and Inla</em>. Chapman; Hall/CRC.</p>
</div>
<div id="ref-Lancaster">
<p>Lancaster, Kelvin J. 1966. “A New Approach to Consumer Theory.” <em>Journal of Political Economy</em> 74 (2): 132–57. <a href="http://www.jstor.org/stable/1828835">http://www.jstor.org/stable/1828835</a>.</p>
</div>
<div id="ref-Lindgren2011">
<p>Lindgren, Finn, Håvard Rue, and Johan Lindström. 2011. “An Explicit Link Between Gaussian Fields and Gaussian Markov Random Fields: The Stochastic Partial Differential Equation Approach.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 73 (4): 423–98. <a href="https://doi.org/10.1111/j.1467-9868.2011.00777.x">https://doi.org/10.1111/j.1467-9868.2011.00777.x</a>.</p>
</div>
<div id="ref-Ling">
<p>Ling, Yuheng. 2019. “Time, Space and Hedonic Prediction Accuracy Evidence from the Corsican Apartment Market.” <em>The Annals of Regional Science</em>, April, 28. <a href="https://doi.org/10.1007/s00168-019-00967-2">https://doi.org/10.1007/s00168-019-00967-2</a>.</p>
</div>
<div id="ref-Malpezzi">
<p>Malpezzi, Stephen. 2008. “Hedonic Pricing Models: A Selective and Applied Review.” In, 67–89. <a href="https://doi.org/10.1002/9780470690680.ch5">https://doi.org/10.1002/9780470690680.ch5</a>.</p>
</div>
<div id="ref-sellingVSrental">
<p>Manganelli, Benedetto, Pierluigi Morano, and Francesco Tajani. 2013. “Economic Relationships Between Selling and Rental Prices in the Italian Housing Market.” In.</p>
</div>
<div id="ref-Blangiardo-Cameletti">
<p>Marta Blangiardo, Michela Cameletti. 2015. <em>Spatial and Spatio-Temporal Bayesian Models with R-Inla</em>. Wiley.</p>
</div>
<div id="ref-Moraga2019">
<p>Moraga, Paula. 2019. <em>Geospatial Health Data</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9780429341823">https://doi.org/10.1201/9780429341823</a>.</p>
</div>
<div id="ref-Moragacovid2020">
<p>Moraga, Paula, David I. Ketcheson, Hernando C. Ombao, and Carlos M. Duarte. 2020. “Assessing the Age- and Gender-Dependence of the Severity and Case Fatality Rates of COVID-19 Disease in Spain.” <em>Wellcome Open Research</em> 5 (June): 117. <a href="https://doi.org/10.12688/wellcomeopenres.15996.1">https://doi.org/10.12688/wellcomeopenres.15996.1</a>.</p>
</div>
<div id="ref-LecturePaci">
<p>Paci, Lucia. 2020. “Statistical Models for High Dimensional and Spatio-Temporal Data.” Università Cattolica del Sacro Cuore, Milano (UCSC).</p>
</div>
<div id="ref-PACI2017149">
<p>Paci, Lucia, María Asunción Beamonte, Alan E. Gelfand, Pilar Gargallo, and Manuel Salvador. 2017. “Analysis of Residential Property Sales Using Space–Time Point Patterns.” <em>Spatial Statistics</em> 21: 149–65. <a href="https://doi.org/https://doi.org/10.1016/j.spasta.2017.06.007">https://doi.org/https://doi.org/10.1016/j.spasta.2017.06.007</a>.</p>
</div>
<div id="ref-Rosen">
<p>Rosen, Sherwin. 1974. “Hedonic Prices and Implicit Markets: Product Differentiation in Pure Competition.” <em>Journal of Political Economy</em> 82 (1): 34–55. <a href="http://www.jstor.org/stable/1830899">http://www.jstor.org/stable/1830899</a>.</p>
</div>
<div id="ref-SHEPPARD19991595">
<p>Sheppard, Stephen. 1999. “Chapter 41 Hedonic Analysis of Housing Markets.” In <em>Applied Urban Economics</em>, 3:1595–1635. Handbook of Regional and Urban Economics. Elsevier. <a href="https://doi.org/https://doi.org/10.1016/S1574-0080(99)80010-8">https://doi.org/https://doi.org/10.1016/S1574-0080(99)80010-8</a>.</p>
</div>
<div id="ref-spateconomshifei">
<p>Shi, Wei, and Lung-fei Lee. 2017. “A Spatial Panel Data Model with Time Varying Endogenous Weights Matrices and Common Factors.” <em>Regional Science and Urban Economics</em> 72 (April). <a href="https://doi.org/10.1016/j.regsciurbeco.2017.03.007">https://doi.org/10.1016/j.regsciurbeco.2017.03.007</a>.</p>
</div>
<div id="ref-simpson2017">
<p>Simpson, Daniel, Håvard Rue, Andrea Riebler, Thiago G. Martins, and Sigrunn H. Sørbye. 2017. “Penalising Model Component Complexity: A Principled, Practical Approach to Constructing Priors.” <em>Statist. Sci.</em> 32 (1): 1–28. <a href="https://doi.org/10.1214/16-STS576">https://doi.org/10.1214/16-STS576</a>.</p>
</div>
<div id="ref-mass">
<p>Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics with S</em>. Fourth. New York: Springer. <a href="http://www.stats.ox.ac.uk/pub/MASS4/">http://www.stats.ox.ac.uk/pub/MASS4/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inla.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exploratory.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false,
"google": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/NiccoloSalvini/thesis/edit/master/05-prd_modelling.Rmd",
"text": "Suggest an edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Niccolo_Salvini_Thesis.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
